<!DOCTYPE html>

<html>
<head>
  <meta content="text/html; charset=utf-8" http-equiv=
  "content-type">
  <meta name="generator" content=
  "HTML Tidy for HTML5 (experimental) for Linux https://github.com/w3c/tidy-html5/tree/c63cc39">
  <meta content="width=device-width,initial-scale=1" name=
  "viewport">

  <title>Data on the Web Best Practices</title>
  <script class="remove" src=
  "http://www.w3.org/Tools/respec/respec-w3c-common">
</script>
  <script class="remove" src="bpconfig.js">
</script>
  <style type="text/css">
#bp-summary ul {
  list-style-type: none;
  padding-left: 0;
  line-height:1.6em;
  background-color: #FCFAEE;
  }
  @media screen and (min-width: 500px) {
  #bp-summary ul {
  column-count:2;
  column-gap: 1em;
  }
  }
  @media screen and (min-width: 800px) {
  #bp-summary ul {
  column-count:3;
  }
  }
  .practice {
  padding-left: 1em;
  background-color: #FCFAEE;
  border-left: thick solid #E0CB52;
  }
  .practice p.practicedesc {
  font-style:italic;
  border-bottom: thin solid black;
  }
  .practice p.subhead {
  font-weight:bold;
  }
  .practice dl dt {
  font-weight:normal;
  }
  </style>
</head>

<body>
  <section id="abstract">
    <p>This document provides best practices designed to improve
    publishing and using of data on the Web. As experience of
    publishing and using data on the Web grows there are further
    issues that need addressing to facilitate interaction between
    data publishers and data consumers. These best practices are
    developed to bridge the gap between them.</p>
  </section>

  <section id="sotd">
    <p>Something here</p>
  </section>

  <section id="intro" class="informative">
    <h2>Introduction</h2>

    <p>In recent years, more and more structured and
    semi-structured data is moving onto the Web. The increasing
    interest on publishing open data together with social media and
    crowdsourcing applications motivates the growth of the volume
    of data available on the Web. On the one hand, data publishers
    aim to share data related to multitude domains, like transport,
    sciences, education, financial, cultural heritage and
    e-commerce. On the other hand, data consumers would like easy
    access to data that is accurate, regularly updated and
    guaranteed to be available at all times.</p>

    <p>A fundamental aspect about publishing and consuming data on
    the Web is having a common understanding between data
    publishers and data consumers. Without this agreement, data
    publishers efforts may be incompatible with data consumers
    desires. In order to achieve the full potential of having data
    on the Web, it is important to facilitate better communication
    between developers and publishers while contributing to develop
    the data on the Web ecosystem.</p>

    <p>Publishing data on the Web creates new challenges, like how
    to represent, describe and make data available on the Web in a
    way that it will be easy to find and to understand these data,
    while it is also possible to trust on them. In this context, it
    becomes crucial to provide guidance to publishers that will
    improve consistency in the way data is managed, thus promoting
    the re-use of data and also to foster trust in the data among
    developers, whatever technology they choose to use, increasing
    the potential for genuine innovation.</p>

    <p>This document sets out a series of best practices mainly
    designed to help to face the new challenges poses by data on
    the Web, while bridges the gap between data publishers and data
    consumers. These best practices are organized around the
    different phases of the Data on the Web lifecycle, which
    provides a plan for considering the several tasks that will
    need to be performed on a data throughout its life on the Web.
    As proposed by [[MOLLER]], data is a living thing that moves
    through various stages, such as creation, publishing, use or
    termination. Best practices can be seen as guidelines that help
    to manage the data on these different phases.</p>

    <p>Best practices cover different aspects related to data
    publishing and consuming, like data formats, data access, data
    identification and metadata. In order to delimit the scope and
    elicit the required features for Data on the Web Best
    Practices, the <acronym title=
    "Data on the Web Best Practices">DWBP</acronym> working group
    compiled a set of <a href="usecasesv1.html">use cases</a> that
    represent scenarios of how data is commonly published on the
    Web and how it is used. The set of requirements derived from
    these use cases were used to guide the development of the
    DWBP.</p>
  </section>

  <section id="audience" class="informative">
    <h2>Audience</h2>

    <p>This document provides guidance to those who publish data on
    the Web, but also to those who consume data on the Web. These
    best practices have been written to meet the needs of many
    different audiences from developers and information management
    staff to scientists interested on sharing data on the Web.
    Every attempt has been made to make the document as readable
    and usable as possible while still retaining the accuracy and
    clarity needed in a technical specification.</p>

    <p>Readers of this document are expected to be familiar with
    some fundamental concepts of the architecture of the Web
    [[WEBARCH]], such as resources and URIs, as well as open data
    formats [[REF]]. Basic knowledge about vocabularies and
    ontologies would be helpful to better understand some aspects
    of this document.</p>
  </section>

  <section id="scope" class="informative">
    <h2>Scope</h2>

    <p>As the goal of the document is to specify Best Practices for
    data on the Web, statements that are not unique to publishing
    or consuming data on the Web are not included. In particular,
    this specification provides best practices to encourage reuse
    or publication of data on the Web.<br>
    All best practices are written as testable criteria for
    objectively determining if they were correctly employed.
    Testing the best practices would involve a combination of
    automated testing and human evaluation.</p>

    <p>Lack of adherence to any given best practice, however, does
    not necessarily imply a lack of quality; they are
    recommendations that are said to be 'best' in most cases and in
    most contexts, but not all. A best practice is always subject
    to improvement as we learn and evolve the Web together.</p>
  </section>

  <section id="context" class="informative">
    <h2>Context</h2>

    <section id="challenges">
      <h2>Data on the Web Challenges</h2>

      <p>The openness and flexibility of the Web creates new
      challenges for data publishers and data consumers. Different
      from conventional databases, for example, where theres is a
      single data model to represent the data and a database
      management system (DBMS) to control data access, data on the
      Web implies to have several ways to represent and to access
      data. Besides, since data publishers and data consumers may
      not belong to the same company, it becomes essential to
      provide information about data quality and data provenance.
      In the same way, data licenses should also be explicitly
      informed. The table below summarizes some of the main
      challenges faced when publishing or consuming data on the
      Web. These challenges were identified from the DWBP Use Cases
      and Requirements and are described by one or more
      questions.</p>

      <dl>
        <dt>Data Formats</dt>

        <dd><em>What kind of data formats should be considered when
        publishing data on the Web?</em></dd>

        <dt>Vocabularies</dt>

        <dd><em>How to use existing vocabularies to provide
        semantic interoperability?<br>
        How to design a new vocabulary when it is not possible to
        use an existing one?</em></dd>

        <dt>Metadata</dt>

        <dd><em>What kind of metadata should be considered when
        describing data on the Web?<br>
        How to describe metadata in a machine readable
        way?</em></dd>

        <dt>Licenses</dt>

        <dd><em>How to describe data licenses in a machine readable
        way?<br>
        How to provide/gather data licenses information about data
        published on the Web?</em></dd>

        <dt>Provenance</dt>

        <dd><em>How to provide/gather data provenance information
        about data published on the Web?</em></dd>

        <dt>Data Granularity</dt>

        <dd><em>What kind of data granularity should be considered
        when publishing data on the Web?</em></dd>

        <dt>Data Access</dt>

        <dd><em>What kind of data access should be considered when
        publishing data on the Web?<br>
        What requirements to take into account when deciding how to
        make data available on the Web?</em></dd>

        <dt>Sensitive Data</dt>

        <dd><em>How to deal with sensitive data in order to not
        infringe a person's right to privacy or an organization's
        security?</em></dd>

        <dt>Data Identification</dt>

        <dd><em>How to provide unique identifiers for data
        resources?<br>
        How to deal with URI Design and management for
        persistence?</em></dd>

        <dt>Preservation</dt>

        <dd><em>How to manage preservation when data on the Web
        should be archived?</em></dd>

        <dt>Data Quality</dt>

        <dd><em>How to provide/gather data quality information
        about data on the Web?</em></dd>

        <dt>Versioning</dt>

        <dd><em>How to track/manage different versions of a data on
        the Web?</em></dd>

        <dt>Feedback</dt>

        <dd><em>How to track/gather user feedback about data
        consumed from the Web?</em></dd>
      </dl>
    </section>

    <section id="lifecycle">
      <h2>Data on the Web Lifecycle</h2>

      <p>Literature presentes a lot of proposals for data
      lifecycles ranging from multimedia data [[HARDMAN]] to
      digital libraries [[LIFECYC]]. In [[MOLLER]] is presented a
      survey of lifecycle models for data-centric domains as well
      as an Abstract Data Lifecycle Model (<acronym title=
      "Abstract Data Lifecycle Model">ADLM</acronym>) composed by a
      set of phases, features and roles, which can be used to
      classify and compare existing lifecycle models. ADLM also
      provides the basis to construct new lifecycle models for
      data-centric domains. According to [[MOLLER]] a generic
      lifecycle model for data-centric domains is composed by the
      following main phases: <em>Ontology development</em>,
      <em>Planning</em>, <em>Creation</em>, <em>Archiving</em>,
      <em>Refinement</em>, <em>Publication</em>, <em>Access</em>,
      <em>External use</em>, <em>Feedback</em> and
      <em>Termination</em>.</p>

      <p>The Data on the Web lifecycle used in this document is an
      instance of ADLM. In the following, the ADLM phases are
      revisited and defined according to the data on the Web
      context. It is important to note that the ontology
      development phase is not included, since it is considered an
      independent phase that can take place a priori.</p>

      <ul>
        <li><em>Planning</em>: this phase concerns the moment when
        the intent to publish data on the Web takes a concrete
        form. It also comprises the selection of data to be
        published</li>

        <li><em>Creation</em>: defines the moment when new data is
        created. It means that the data did not exist on the
        Web</li>

        <li><em>Archiving</em>: this phase concerns the process of
        anchoring a piece of data within the system by the means of
        indexing, cataloguing or a similar activity</li>

        <li><em>Refinement</em>: this phase covers all kinds of
        activities which make additions or changes to data that
        already exist in the Web</li>

        <li><em>Publication</em>: this phase concerns the moment
        when data is made accessible on the Web</li>

        <li><em>Access</em>: denotes the moment in the lifecycle
        when users gain access to the data available on the
        Web</li>

        <li><em>External use</em>: implies that the user performs
        some further actions to create visualizations and to
        perform data analysis, for example</li>

        <li><em>Feedback</em>: allows users to comment on the data
        or metadata available on the Web they have previously
        accessed and used</li>

        <li><em>Termination</em>: presents the moment when data is
        removed from the Web</li>
      </ul>

      <p>As proposed in [[MOLLER]], the data on the Web lifecycle
      model is an evolving one, since there is no restriction for
      data to pass through all phases of the lifecycle before the
      start of a new iteration, neither a specific point of the
      lifecyle to begin with.</p>

      <p>In the data on the Web context, two main roles may be
      played by actors in the lifecycle: data publisher and data
      consumer. The data publisher role may be played by several
      actors who are responsible for performing actions like data
      and metadata creation, and data publication and archiving.
      The data consumer are these actors who receive and consume
      the data.</p>
    </section>
  </section>

  <section id="bp-summary"></section>

  <section id="bestPractices">
    <h2>The Best Practices</h2>

    <section id="dataCreation">
      <h3>Best Practices for Data Creation and Publication</h3>

      <p>Intro to data organization section here.</p>

      <section id="metadata">
        <h4>Metadata</h4>

        <p>Metadata is data about data. It provides additional information
        about data, to help consumers better understand the meaning
        of data, its structure, and to clarify other issues, as for
        example, license of use, the organization that generated
        the data, data quality, data access, the update schedule of
        datasets, etc.</p>

        <p>Metadata can be used to help tasks as, for example,
        dataset discovery and reuse, and can
        be assigned considering different granularity that goes
        from a single property of a resource to a whole dataset, or
        all datasets from a specific organization.</p>

        <p>Metadata SHOULD be available in human-readable
        and machine-readable forms. It is important to provide both forms
        of metadata in order to reach humans and applications. In
        the case of machine-readable metadata, the use of standard
        vocabularies should be encouraged as a way of enhancing
        common semantics. For example, data provenance could be
        described using PROV-O, a W3C Recommendation that provides
        a set of classes, properties, and restrictions that can be
        used to represent and interchange provenance information
        generated in different systems and under different
        contexts.</p>

        <p>Metadata can be of different types. These types can be
        classified in different taxonomies, with different grouping
        criterias. For example, a specific taxonomy could define
        three metadata types according to descriptive, structural
        and administrative features. Descriptive metadata serves to
        identify a dataset, structural metadata serves to
        understand the format that the dataset is distributed and
        administrative metadata serves to provide information about
        version, update schedule, etc. A different taxonomy could
        define metadata types with a scheme according to tasks
        where metadata are used, for example, discovery and
        reuse.</p>

        <p>Is out of the scope of this document to talk about
        metadata types related to dataset distribution formats,
        for example, CSV files, Linked Data, etc. Each format has
        its particular metadata scheme and different W3C groups are
        responsible for defining each of these standards. Taking
        the CSV example, W3C CSV on the Web WG has the mission of
        providing technologies whereby data dependent applications
        on the Web can provide higher interoperability when working
        with datasets using the CSV (Comma-Separated Values) or
        similar formats. In this document we will talk about some types of
        metadata that are common to datasets, independently of the
        domain or the distribution format.</p>

        <section class="issue">
          <p>At TPAC we talked about the distinction between
          discovery metadata and structural metadata. These are not
          (yet) reflected here although <a href=
          "http://www.w3.org/2013/dwbp/track/issues/76">Issue-76</a>
          looks relevant. New <a href=
          "https://www.w3.org/2013/dwbp/track/issues/79">issue-79</a>
          opened.</p>
        </section>
      </section>

      <section id="licenses">
        <h4>Data Licenses</h4>

        <p>The section on licenses</p>

        <div class="practice">
          <p><span class="practicelab">License</span></p>

          <p class="practicedesc">Data must be associated with a
          license.</p>

          <div class="axioms">
            <p class="subhead">Why</p>

            <dl>
              <dt>Why this is unique to publishing data on the
              Web</dt>

              <dd>Something here to answer this question</dd>

              <dt>How this encourages publication or reuse of data
              on the Web</dt>

              <dd>Something here to answer this question</dd>
            </dl>
          </div>

          <div class="description">
            <p class="subhead">What</p>

            <p>Full text description goes here. It can be any
            length but is likely to be no more than a few
            sentences. Maybe more. I mean, some things just can't
            be expressed in a few sentences. There may even by
            diagrams (I like pictures).</p>

            <p>Anyway, you get this idea, no more than the
            sufficient amount of text to convey the best
            practice.</p>

            <p class="subhead">Intended outcome</p>

            <p>What it should do</p>
          </div>

          <div class="how">
            <p class="subhead">Possible Approach to
            Implementation</p>

            <p>Description of how to implement the BP.</p>
          </div>

          <div class="test">
            <p class="subhead">How to Test</p>

            <p>Information on how to test the BP has been met. This
            might or might not be machine testable.</p>
          </div>

          <div class="ucr">
            <p class="subhead">Evidence</p>

            <p><span>Relevant use cases</span>: R-AccessBulk,
            R-FormatOpen, R-VocabOpen etc.</p>
          </div>
        </div>

        <div class="practice">
          <p><span class="practicelab">Machine detectable
          License</span></p>

          <p class="practicedesc">A License should be detectable by
          machines</p>

          <div class="axioms">
            <p class="subhead">Why</p>

            <dl>
              <dt>Why this is unique to publishing data on the
              Web</dt>

              <dd>Because the Web is a network of machines that can
              do cool stuff if they are given a chance</dd>

              <dt>How this encourages publication or reuse of data
              on the Web</dt>

              <dd>Machines, including search engines, can be set up
              to automatically harvest data that has an associated
              license</dd>
            </dl>
          </div>

          <div class="description">
            <p class="subhead">What</p>

            <p>Full text description goes here. It can be any
            length but is likely to be no more than a few
            sentences. Maybe more. I mean, some things just can't
            be expressed in a few sentences. There may even by
            diagrams (I like pictures).</p>

            <p>Anyway, you get this idea, no more than the
            sufficient amount of text to convey the best
            practice.</p>

            <p class="subhead">Intended outcome</p>

            <p>Machines can automatically detect whether a given
            dataset does or does not carry a license.</p>
          </div>

          <div class="how">
            <p class="subhead">Possible Approach to
            Implementation</p>

            <p>Link to a CC license</p>
          </div>

          <div class="test">
            <p class="subhead">How to Test</p>

            <p>Look for a link element ot HTTP Link Header with a
            @rel value of <code>license</code> [[RFC4946]]</p>
          </div>

          <div class="ucr">
            <p class="subhead">Evidence</p>

            <p><span>Relevant use cases</span>: R-AccessBulk,
            R-FormatOpen, R-VocabOpen etc.</p>
          </div>
        </div>
      </section>

      <section id="quality">
        <h4>Data Quality</h4>

        <p>The section on data quality</p>
      </section>

      <section id="provenance">
        <h4>Data Provenance</h4>

        <p>The section on provenance</p>
      </section>

      <section id="granularity">
        <h4>Data Granularity</h4>

        <p>The section on granularity</p>
      </section>

      <section id="sensitive">
        <h4>Data Sensitive</h4>

        <p>The section on data sensitive</p>
      </section><!-- End metadata -->

      <section id="dataFormats">
        <h4>Data Formats</h4>

        <p>Best practices on data formats include considerations on
        making data available in multiple open and machine readable
        formats for example RDF and JSON. In addition this section
        will include guidance on preferred data formats for example
        preferred formats for date, string and numbers. Guidance
        will also be provided on expressing data in multiple
        languages. While mentioned in the use case document as
        challenge, the best practices document should not make
        recommendations regarding the formats of source data for
        example database dumps, spreadsheets. It is expected that
        data sources for data on the web will continue to be in
        multiple formats.</p>
      </section>

      <section id="dataVocabularies">
        <h4>Data Vocabularies</h4>

        <p>Datasets often resort to a range of vocabularies in the
        data they contain: data values are entered or captured in a
        controlled way, i.e., for certain positions in a data graph
        (or column in a relationship table), the value used should
        come with a limited set of pre-existing resources: for
        example object types, roles of a person, countries in a
        geographic area, or possible subjects for books. Such
        vocabularies aim to represent a set of terms and the
        relationship among them, in order to ensure a level of
        control, standardization and interoperability in the data.
        They can also provide a way to easily create richer data.
        Say, a dataset contain one reference in a data statement to
        a concept description in several languages. This single
        statement allows applications to localize their display of
        their search depending on the language of the user. The
        vocabularies can also have different forms (e.g. thesaurus,
        taxonomy, semantic network) and be represented in different
        formats (e.g. RDF, OWL, JSON, CSV). This section presents
        best practices for data vocabularies accessible as URI sets
        on the Web. It focuses on the description of Best Practices
        to two different types of audiences: publishers and
        consumers of data vocabularies.</p>
      </section>

      <section id="dataIdentification">
        <h4>Data Identification</h4>

        <div class="practice">
          <p><span class="practicelab">Identifier</span></p>

          <p class="practicedesc">All datasets must have a unique,
          persistent identifier</p>

          <div class="axioms">
            <p class="subhead">Why</p>

            <dl>
              <dt>Why this is unique to publishing data on the
              Web</dt>

              <dd>Because the Web is built on links and this is
              kind of basic stuff</dd>

              <dt>How this encourages publication or reuse of data
              on the Web</dt>

              <dd>A stable reference ensures long term
              discoverability and citations.</dd>
            </dl>
          </div>

          <div class="description">
            <p class="subhead">What</p>

            <p>Full text description goes here. It can be any
            length but is likely to be no more than a few
            sentences. Maybe more. I mean, some things just can't
            be expressed in a few sentences. There may even by
            diagrams (I like pictures).</p>

            <p>Anyway, you get this idea, no more than the
            sufficient amount of text to convey the best
            practice.</p>

            <p class="subhead">Intended outcome</p>

            <p>That the dataset be discoverable and citable today
            and in future.</p>
          </div>

          <div class="how">
            <p class="subhead">Possible Approach to
            Implementation</p>

            <p>Well now we're getting into URI design and, for
            those that want them, DOIs and all that.</p>
          </div>

          <div class="test">
            <p class="subhead">How to Test</p>

            <p>Apply the design rules...</p>
          </div>

          <div class="ucr">
            <p class="subhead">Evidence</p>

            <p><span>Relevant use cases</span>: R-AccessBulk,
            R-FormatOpen, R-VocabOpen etc.</p>
          </div>
        </div>
      </section>
    </section><!-- end data Creation -->

    <section id="dataPublication">
      <h3>Best Practices for Data Access, Refinement and
      Archiving</h3>

      <p>Intro to data publication section</p>

      <section id="dataAccess">
        <h4>Data Access</h4>
      </section>

      <section id="dataPreservation">
        <h4>Data Preservation</h4>

        <p>Data preservation is a well understood and commonly
        performed tasks for static and self-contained data. This
        commonly includes the following steps:</p>

        <ul>
          <li>Ingest the data and assign a persistent identifier to
          it</li>

          <li>Ensure the data is correctly stored and prevent bit
          rot</li>

          <li>Provide access to the data and perform format
          translation if needed</li>
        </ul>

        <p>The model most commonly referred to is <a href=
        "http://en.wikipedia.org/wiki/Open_Archival_Information_System">
        Open Archival Information System</a>. Many institutions
        taking care of digital preservation are implementing this
        model or some variant of it. Web pages can be preserved
        following the same strategies, considering a web site as a
        static data set that is self-contained and can be all
        snap-shoted and preserved at a fixed time. When it comes to
        Web data some new elements have to be taken into account,
        namely:</p>

        <ul>
          <li>The persistent identifiers (IRI) used across the web
          are related to live data that can change</li>

          <li>The meaning of a resource is contextualized by the
          other resources it is linked to</li>

          <li>Documents fetched in HTML, RDF of JSON, for instance,
          are only one of the many possible serialisation of the
          data they represent</li>
        </ul>

        <p>The preservation of Web data should generaly focus on
        the preservation of the description of entities.</p>

        <div class="practice">
          <p><span id="list_resources" class="practicelab">Maintain
          a list of resources described in a dataset</span></p>

          <p class="practicedesc">A dataset should be preserved
          together with a list of all the resources it
          describes</p>

          <section class="axioms">
            <p class="subhead">Why</p>

            <ul>
              <li>Web data is about the description of resources
              identified with a IRI.</li>

              <li>It is to be expected that queries made by data
              consumers will resolve around finding a preserved
              description about a particular resource.</li>
            </ul>
          </section>

          <section class="description">
            <p class="subhead">What</p>

            <p>Web data is essentially about the description of
            entities identified by a unique, Web-based, identifier
            (a URI). Once the data is dumped and sent to a
            institute specialised in digital preservation the link
            with the Web is broken (de-referencing) but the role of
            the URI as a unique identifier still remains. In order
            to increase the usability of preserved dataset dumps it
            is relevant to maintain a list of these
            identifiers.</p>
          </section>

          <section class="outcome">
            <p class="subhead">Intended Outcome</p>

            <p>A list of resources described in a dataset</p>
          </section>

          <section class="how">
            <p class="subhead">Possible Approach to
            Implementation</p>

            <p>The list of resources can be created by the data
            depositor or the digital repository at ingestion time.
            A dataset dump is scanned for all the subject described
            and this list is stored separately. For RDF and
            JSON-LD, this corresponds to all the resources in the
            "subject" position of statements.</p>
          </section>

          <section class="test">
            <p class="subhead">How to Test</p>

            <p>Every resource listed in the resource list must have
            some kind of description in the dataset</p>
          </section>

          <section class="ucr">
            <p class="subhead">Evidence</p>

            <p><span>Relevant requirements</span>:<a href=
            "http://w3c.github.io/dwbp/usecasesv1.html#R-UniqueIdentifier">R-UniqueIdentifier</a></p>
          </section>
        </div>

        <div class="practice">
          <p><span id="evaluate" class="practicelab">Assess dataset
          coverage</span></p>

          <p class="practicedesc">The coverage of a dataset should
          be assessed prior to its preservation</p>

          <section class="axioms">
            <p class="subhead">Why</p>

            <ul>
              <li>A chunk of Web data is by definition dependent on
              the rest of the global graph. This global context
              influences the meaning of the description of the
              resources found in the dataset.</li>

              <li>Ideally, the preservation of a particular dataset
              would involve preserving all its context. That is the
              entire Web of Data.</li>
            </ul>
          </section>

          <section class="description">
            <p class="subhead">What</p>

            <p>At ingestion time an evaluation of the linkage of
            Web data dataset dump to already preserved resources is
            assessed. The presence of all the vocabularies and
            target resources in uses is sought in a set of digital
            archives taking care of preserving Web data. Datasets
            for which very few of the vocabularies used and/or
            resources pointed out are already preserved somewhere
            should be flagged as being at risk.</p>
          </section>

          <section class="outcome">
            <p class="subhead">Intended Outcome</p>

            <p>An evaluation of the preservation coverage for a
            given dataset. The outcome of this evaluation should be
            used to take an informed decision concerning the
            ingestion, or not, of the dataset</p>
          </section>

          <section class="how">
            <p class="subhead">Possible Approach to
            Implementation</p>

            <p>The assessement could be performed by the digital
            preservation institute or the dataset depositor. It
            essentially consists in checking whether all the
            resources used are either already preserved somewhere
            or provided along with the new dataset considered for
            preservation.</p>
          </section>

          <section class="test">
            <p class="subhead">How to Test</p>

            <p>Datasets making references to portions of the Web of
            Data which are not preserved should receive a lower
            score than those using common resources.</p>
          </section>

          <section class="ucr">
            <p class="subhead">Evidence</p>

            <p><span>Relevant requirements</span>:<a href=
            "http://w3c.github.io/dwbp/usecasesv1.html#R-VocabReference">R-VocabReference</a></p>
          </section>
        </div>

        <div class="practice">
          <p><span id="serialisation" class="practicelab">Data
          dumps should use a trusted serialisation
          format</span></p>

          <p class="practicedesc">Data depositors willing to send a
          datadump for long term preservation should use a well
          established serialisation</p>

          <section class="axioms">
            <p class="subhead">Why</p>

            <ul>
              <li>Web data is a abtract data model that can be
              expressed in different ways (RDF, JSON-LD, ...)</li>

              <li>Using a well established serialisation of this
              data increases its chances of re-use</li>
            </ul>
          </section>

          <section class="description">
            <p class="subhead">What</p>

            <p>Institute doing digital preservation are tasked with
            monitoring file format obsolescence. Datasets which
            have been acquierd in some format some years ago may
            have to be converted into another format in order to
            still be usable with more modern software (see
            [[ROSENTHAL]]). This tasks can be made more challenge,
            or even impossible, if non standard serialisation
            formats are used by data depositors.</p>
          </section>

          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
          </section>

          <section class="how">
            <p class="subhead">Possible Approach to
            Implementation</p>

            <p>Give preference to Web data serialisation formats
            available as open standards. For instance those
            provided by the W3C.</p>
          </section>

          <section class="test">
            <p class="subhead">How to Test</p>

            <p>Try to open the data dump with different
            software.</p>
          </section>

          <section class="ucr">
            <p class="subhead">Evidence</p>

            <p><span>Relevant requirements</span>:<a href=
            "http://w3c.github.io/dwbp/usecasesv1.html#R-Archive">R-Archive</a></p>
          </section>
        </div>

        <div class="practice">
          <p><span id="resourcestatus" class="practicelab">Update
          the status of a URI</span></p>

          <p class="practicedesc">Preserved datasets should be
          linked with their "live" counterparts</p>

          <section class="axioms">
            <p class="subhead">Why</p>

            <ul>
              <li>URI dereferencing is a primary interface to Web
              data</li>

              <li>Linking preserved datasets with resolving URI
              inform the data consumer of the status of these
              resources</li>
            </ul>
          </section>

          <section class="description">
            <p class="subhead">What</p>

            <p>During its live cycle a Web data dataset may undergo
            several modifications. Although IRIs assigned to things
            are not expected to change, the description of these
            resource will evolve over time. There are also some new
            IRIs that will be put into use, some other that will
            become deprecated, and some that will get deleted.
            Along to this evolution several snapshots could be made
            available for preservation. An example of this is
            DBpedia which has undergo several releases since its
            first publication and always use the same IRI for its
            resources. Every resource is de-referenced to the most
            up to date description available for it along with a
            link to preserved descriptions using the protocol
            Memento (see <a href=
            "http://mementoweb.org/depot/native/dbpedia/">Memento
            gateway for DBpedia</a>)</p>
          </section>

          <section class="outcome">
            <p class="subhead">Intended Outcome</p>

            <p>A link is maintained between the IRI of a things,
            the most up-to-date description available for it and
            preserved descriptions. If the resource does not exist
            any more the description should say so and refer to the
            last preserved description that was available for
            it.</p>
          </section>

          <section class="how">
            <p class="subhead">Possible Approach to
            Implementation</p>

            <p>There is a variety of HTTP status code that could be
            put into use to relate the IRI with its preserved
            description. In particular, 200, 404, 410, 303 and 209
            can be used for different scenarios:</p>

            <ul>
              <li>200 =&gt; there is a new description which
              contains pointers to archived description</li>

              <li>404 =&gt; the resource just died, the URI
              consumer has to go find an archive to look for
              it</li>

              <li>410 =&gt; dead again but this time it's a
              controlled process</li>

              <li>303 =&gt; the description of this URI is no
              longer served here but there is a preserved
              description at a different location</li>

              <li>209 =&gt; this resource does not exist any more
              but we have some information about it. The
              description could include a list of locations having
              different preserved descriptions over different
              times.</li>
            </ul>Next to the status codes, HTTP header can also be
            used to relate resources.
          </section>

          <section class="test">
            <p class="subhead">How to Test</p>

            <p>The presence of relations can be checked with a
            software looking for links between all the target
            resources</p>
          </section>

          <section class="ucr">
            <p class="subhead">Evidence</p>

            <p><span>Relevant requirements</span>:<a href=
            "http://w3c.github.io/dwbp/usecasesv1.html#R-DataUnavailabilityReference">R-DataUnavailabilityReference</a>,
            <a href=
            "http://w3c.github.io/dwbp/usecasesv1.html#R-PersistentIdentification">
            R-PersistentIdentification</a></p>
          </section>
        </div>
      </section><!-- data archiving -->

      <section id="dataVersioning">
        <h4>Data Versioning</h4>
      </section><!-- data refinement -->
    </section>

    <section id="dataUsage">
      <h3>Best Practices for External Use and Feedback</h3>

      <p>The data usage section</p>

      <section id="enrichment">
        <h4>Data Enrichment</h4>
      </section><!-- data enrichment -->

      <section id="usageFeedback">
        <h4>Data Usage Feedback</h4>
      </section>
    </section><!-- Feedback -->
  </section><!-- end best practices -->

  <section id="conclusions">
    <h2>Conclusions</h2>
  </section>

  <section>
    <h2>BP Template</h2>

    <p>See <a href=
    "http://www.w3.org/respec/guide.html">http://www.w3.org/respec/guide.html</a></p>

    <div class="practice">
      <p><span id="template" class="practicelab">Best Practice
      Title</span></p>

      <p class="practicedesc">Short description of the BP, pref one
      line</p>

      <section class="axioms">
        <p class="subhead">Why</p>

        <dl>
          <dt>Why this is unique to publishing data on the Web</dt>

          <dd>Something here to answer this question</dd>

          <dt>How this encourages publication or reuse of data on
          the Web</dt>

          <dd>Something here to answer this question</dd>
        </dl>
      </section>

      <section class="description">
        <p class="subhead">What</p>

        <p>Full text description goes here. It can be any length
        but is likely to be no more than a few sentences. Maybe
        more. I mean, some things just can't be expressed in a few
        sentences. There may even by diagrams (I like
        pictures).</p>

        <p>Anyway, you get this idea, no more than the sufficient
        amount of text to convey the best practice.</p>
      </section>

      <section class="outcome">
        <p class="subhead">Intended Outcome</p>

        <p>What it should do</p>
      </section>

      <section class="how">
        <p class="subhead">Possible Approach to Implementation</p>

        <p>Description of how to implement the BP.</p>
      </section>

      <section class="test">
        <p class="subhead">How to Test</p>

        <p>Information on how to test the BO has been met. This
        might or might not be machine testable.</p>
      </section>

      <section class="ucr">
        <p class="subhead">Evidence</p>

        <p><span>Relevant requirements</span>: R-AccessBulk,
        R-FormatOpen, R-VocabOpen etc.</p>
      </section>
    </div>
  </section>
</body>
</html>
