<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Data on the Web Best Practices Use Cases &amp; Requirements</title>
    <!--[if lt IE 9]>
  <script src="http://www.w3.org/2008/site/js/html5shiv.js"></script>  <![endif]-->
    <script src="https://www.w3.org/Tools/respec/respec-w3c-common" class="remove"></script>
    <script class="remove">
      var respecConfig = {

          // specification status (e.g. WD, LC, WG-NOTE, etc.). If in doubt use ED.
          specStatus:           "ED", 
          //specStatus:           "CR",


          // the specification's short name, as in http://www.w3.org/TR/short-name/
          shortName:            "dwbp-ucr",

          // if your specification has a subtitle that goes below the main
          // formal title, define it here
          // subtitle   :  "an excellent document",

          // if you wish the publication date to be other than today, set this
         // publishDate:  "2013-12-17", 
         // prEnd:        "2014-01-12",
         // lcEnd:        "2013-11-26", 
         // crEnd:        "2013-11-26",

          // if the specification's copyright date is a range of years, specify
          // the start date here:
          copyrightStart: "2014",

          // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
          // and its maturity status
      	  previousPublishDate:  "2014-16-05", 
          //previousPublishDate:  "2013-08-01",
          //previousMaturity:  "CR",
          previousMaturity:  "FPWD",
          
          // if there a publicly available Editor's Draft, this is the link
          edDraftURI:           "http://w3c.github.io/dwbp/usecasesv1.html",

          // if this is a LCWD, uncomment and set the end of its review period
          // lcEnd: "2013-09-06",

          // if there is an earler version of this specification at the Recommendation level,
          // set this to the shortname of that version. This is optional and not usually
          // necessary.
	  //          prevRecShortname: "rdf-concepts",

          // editors, add as many as you like
          // only "name" is required

	  editors:  [
	  { name: "Deirdre Lee", url: "mailto:deirdre.lee@insight-centre.org", company: "Insight@NUIG, Ireland", companyURL: "http://www.insight-centre.org/"},
	  { name: "Bernadette Farias Lóscio", url: "mailto:bfl@cin.ufpe.br", company: "Centro de Informática - Universidade Federal de Pernambuco, Brazil", companyURL: "http://www.cin.ufpe.br/" },
    {name: "Phil Archer", url: "mailto:phila@w3.org", company: "W3C/ERCIM", companyURL: "http://www.w3.org/"}
	  ],

          // authors, add as many as you like.
          // This is optional, uncomment if you have authors as well as editors.
          // only "name" is required. Same format as editors.

          //authors:  [
          //    { name: "Your Name", url: "http://example.org/",
          //      company: "Your Company", companyURL: "http://example.com/" },
          //],

          // name of the WG
	  wg:           "Data on the Web Best Practices Working Group",


          // URI of the public WG page
	  wgURI:        "http://www.w3.org/2013/dwbp/",

          // name (WITHOUT the @w3.org) of the public mailing to which comments are due
	  wgPublicList: "public-dwbp-comments",


          // URI of the patent status for this WG, for Rec-track documents
          // !!!! IMPORTANT !!!!
          // This is important for Rec-track documents, do not copy a patent URI from a random
          // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
          // Team Contact.
          wgPatentURI:  "http://www.w3.org/2004/01/pp-impl/68239/status",

          // if this parameter is set to true, ReSpec.js will embed various RDFa attributes
          // throughout the generated specification. The triples generated use vocabulary items
          // from the dcterms, foaf, and bibo. The parameter defaults to false.
          doRDFa: "1.1",

          alternateFormats: [ { uri: "diff-20131105.html", label: "diff to previous version" } ],

	 // implementationReportURI: "http://www.w3.org/2011/gld/wiki/DCAT_Implementations",
	  maxTocLevel: 2,

      };
    </script>
    <link rel="stylesheet" href="http://www.w3.org/TR/2014/WD-dwbp-ucr-20140605/localstyles.css" />
    <style type="text/css">
    caption {
      caption-side:bottom;
      margin-top:0.3em;
      font-style:italic;
    }
    </style>
  </head>
  <body>
    <section id="abstract">
      <p>This document lists use cases, compiled by the Data on the
        Web Best Practices Working Group, that represent scenarios of how data
        is commonly published on the Web and how it is used. This document also
        provides a set of requirements derived from these use cases that will be
        used to guide the development of the set of Data on the Web Best
        Practices and the development of two new vocabularies: Quality and
        Granularity Description Vocabulary and Data Usage Description
        Vocabulary. </p>
    </section>
    <section id="sotd"> </section>
    <section class="informative">
      <h2 id="intro">Introduction</h2>
      <p>There is a growing interest in publishing and consuming data on the
        Web. Both government and non-government organizations already make a
        variety of data available on the Web, some openly, some with access 
        restrictions, covering many domains like education, the economy, 
        security, cultural heritage, eCommerce and scientific data. 
        Developers, journalists and others manipulate this data to create 
        visualizations and to perform data analysis. Experience in this field 
        shows that several important issues need to be addressed in order to 
        meet the requirements of both data publishers and data consumers. </p>
      <p>To address these issues, the Data on the Web Best Practices Working
        Group seeks to provide guidance to all stakeholders that will improve
        consistency in the way data is published, managed, referenced and used on the Web. 
        The guidance will take two forms: a set of best practices that
        apply to multiple technologies, and vocabularies that are currently missing but
        that are needed to support the data ecosystem on the Web.</p>
      <p>In order to determine the scope of the best practices and the
        requirements for the new vocabularies, a set of use cases has been
        compiled. Each use case provides a narrative describing an experience of
        publishing and using Data on the Web. The use cases cover different
        domains and illustrate some of the main challenges faced by data
        publishers and data consumers. A set of requirements, used to guide the
        development of the set of best practices as well as the development of
        the vocabularies, have been derived from the compiled use cases. </p>
      <div class="issue">
        <p>This is the second Working Draft and is believed to be a relatively mature
          reflection of the major issues. The Working Group is therefore particularly keen to
          receive comments and new use cases to ensure that its future work is relevant, useful and
          comprehensive. Please send comments to <a href="mailto:public-dwbp-comments@w3.org">public-dwbp-comments@w3.org</a>
          (<a href="mailto:public-dwbp-comments-request@w3.org?subject=subscribe">subscribe</a>,
          <a href="http://lists.w3.org/Archives/Public/public-dwbp-comments/">archives</a>).</p>
        <p>There are some outstanding <a href="http://www.w3.org/2013/dwbp/track/issues/raized">issues</a>
          associated with the use cases presented here that are being addressed.
          Where those issue are related to a specific use case or requirement,
          they are highlighted in the body of the document below.</p>
      </div>
    </section>

    <section>
      <h2 id="use-cases">Use Cases</h2>
      <p>A use case illustrates an experience of
        publishing and using Data on the Web. The information gathered from the
        uses cases should be helpful for the identification of the best
        practices that will guide the publishing and usage of Data on the Web.
        In general, a use case will be described at least by a statement
        and a discussion of how the use case is currently implemented. Use case
        descriptions demonstrate some of the main challenges faced by publishers
        or developers. Information about challenges will be helpful to identify
        areas where Best Practices are necessary. According to the challenges, a
        set of requirements are abstracted in such a way that a requirement
        motivates the creation of one or more best practices.</p>


      <!-- Building Eye -->

      <section id="UC-BuildingEye" typeof="bibo:Chapter" resource="#UC-BuildingEye" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-BuildingEye">BuildingEye: SME use of public data</h3>
        <p class="contributor">(Contributed by Deirdre Lee)<br />
          URL: <a href="http://mypp.ie/">http://mypp.ie/</a></p>
        <p>Buildingeye.com makes building and planning information easier to
          find and understand by mapping what's happening in your city. In
          Ireland local authorities handle planning applications and usually
          provide some customized views of the data (PDFs, maps, etc.) on their
          own Web site. However there isn't an easy way to get a nationwide view
          of the data. BuildingEye, an independent SME, built <a href="http://mypp.ie/">http://mypp.ie/</a>
          to achieve this. However as each local authority didn't have an Open
          Data portal, BuildingEye had to directly ask each local authority for
          its data. It was granted access to some authorities, but not all. The
          data it did receive was in different formats and of varying
          quality/detail. BuildingEye harmonized this data for its own system.
          However, if another SME wanted to use this data, they would have to go
          through the same process and again go to each local authority asking
          for the data. </p>
        <p> <strong>Elements:</strong> </p>
        <ul>
          <li><b><i>Domains:</i></b> Planning data</li>
          <li><b><i>Obligation/motivation:</i></b> demand from SME</li>
          <li><b><i>Usage:</i></b> Commercial usage</li>
          <li><b><i>Quality:</i></b> standardized, interoperable across local
            authorities</li>
          <li><b><i>Size:</i></b> medium</li>
          <li><b><i>Type/format:</i></b> structured according to legacy system
            schema</li>
          <li><b><i>Rate of change:</i></b> daily</li>
          <li><b><i>Potential audience:</i></b> Business, citizens</li>
          <li><b><i>Governance:</i></b> local authorities</li>
        </ul>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Access to data is currently a manual process, on a case by case basis</li>
          <li>Data is provided in different formats, e.g. database dumps, spreadsheets</li>
          <li>Data is structured differently, depending on the legacy system schema, concepts and terms not interoperable</li>
          <li>No official Open license associated with the data</li>
          <li>Data is not available for further reuse by other parties</li>
        </ul>
        <p> <strong>Potential Requirements:</strong> </p>
        <ul>
          <li>Creation of top-down policy on open data to ensure common understanding and approach</li>
          <li>Top-down guidance on recommended Open license usage</li>
          <li>Standardized, non-proprietary formats</li>
          <li>Availability of recommended domain-specific vocabularies.</li>
        </ul>
        <p> <strong>Requires:</strong> 
          <a href="#R-FormatMachineRead">R-FormatMachineRead</a>,
          <a href="#R-FormatStandardized">R-FormatStandardized</a>, 
          <a href="#R-FormatOpen">R-FormatOpen</a>,
          <a href="#R-LicenseAvailable">R-LicenseAvailable</a>, 
          <a href="#R-AccessBulk">R-AccessBulk</a>,
          <a href="#R-DataUnavailabilityReference">R-DataUnavailabilityReference</a>,
          <a href="#R-DataMissingIncomplete">R-DataMissingIncomplete</a>,
          <a href="#R-DataLifecyclePrivacy">R-DataLifecyclePrivacy</a> and
          <a href="R-SensitiveSecurity">R-SensitiveSecurity</a>.</p>
      </section>

      <!-- The Land Portal -->

      <section id="UC-TheLandPortal" rel="bibo:Chapter" resource="#h3_UC-TheLandPortal" typeof="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-TheLandPortal">The Land Portal</h3>
        <p class="contributor">(Contributed by Carlos Iglesias)<br />
          URL: <a href="http://landportal.info/">http://landportal.info/</a></p>
        <p>The IFAD Land Portal platform has been completely rebuilt as an Open
          Data collaborative platform for the Land Governance community. Among
          the new features the Land Portal provides access to more than 
          100 indicators from more than 25 different sources on land
          governance issues for more than 200 countries over the world, as well as a
          repository of land related-content and documentation. Thanks to the
          new platform people could</p><ol><li>curate and incorporate new data and
          metadata by means of different data importers and making use of the
          underlying common data model;</li><li>search, explore and compare the data
          through countries and indicators; and</li><li>consume and reuse the data
          by different means (i.e. raw data download at the data catalog; linked
          data and SPARQL endpoint at RDF triplestore; RESTful API; and built-in
          graphic visualization framework).</li></ol>
        <p><strong>Elements:</strong></p>
        <ul>
          <li><b><i>Domains:</i></b> Land Governance; Development</li>
          <li><b><i>Obligation/motivation:</i></b> To find reliable data driven
            indicators on land governance and put all them together to
            facilitate access, study, analysis, comparison and data gaps
            detection.</li>
          <li><b><i>Usage:</i></b> Research; Policy Making, Journalism;
            Development; Investments; Governance; Food security; Poverty; Gender
            issues.</li>
          <li><b><i>Quality:</i></b> Every sort of data, from high quality to
            unverified.</li>
          <li><b><i>Size:</i></b> Varies, but low-medium in general.</li>
          <li><b><i>Type/format:</i></b> Varies: APIs; JSON; spreadsheets; CSV;
            HTML; XML; PDF...</li>
          <li><b><i>Rate of change:</i></b> Usually yearly, but also higher rates
            (monthly, quarterly...).</li>
          <li><b><i>Data lifespan:</i></b> Unlimited.</li>
          <li><b><i>Potential audience:</i></b> Practitioners; Policy makers;
            Activists; Researchers; Journalists.</li>
        </ul>
        <p><strong>Challenges:</strong></p>
        <ul>
          <li>Data coverage.</li>
          <li>Quality of data and metadata.</li>
          <li>Lack of machine-readable metadata.</li>
          <li>Inconsistency between different data sources.</li>
          <li>Wide variety of formats and technologies.</li>
          <li>Some non machine-readable formats.</li>
          <li>Data variability (models, sources, etc.).</li>
          <li>Data provenance.</li>
          <li>Diversity and (sometimes) complexity of Licenses.</li>
          <li>Internationalization issues (e.g. different formats for numbers,
            dates, etc.) and multilingualism.</li>
        </ul>
        <p><strong>Potential Requirements:</strong></p>
        <ul>
          <li>Availability of general use taxonomies (countries, topics, etc.).</li>
          <li>Data interoperability i.e. domain-specific vocabularies for a
            common data model with reference formats and protocols.</li>
          <li>Data persistence.</li>
          <li>Versioning mechanisms.</li>
        </ul>
        <p><strong>Requires:</strong> 
          <a href="#R-MetadataMachineRead">R-MetadataMachineRead</a>,
          <a href="#R-GranularityLevels">R-GranularityLevels</a>, 
          <a href="#R-FormatMachineRead">R-FormatMachineRead</a>,
          <a href="#R-FormatStandardized">R-FormatStandardized</a>, 
          <a href="#R-FormatLocalize">R-FormatLocalize</a>,
          <a href="#R-VocabReference">R-VocabReference</a>, 
          <a href="#R-VocabVersion">R-VocabVersion</a>,
          <a href="#R-ProvAvailable">R-ProvAvailable</a>, 
          <a href="#R-AccessBulk">R-AccessBulk</a>,
          <a href="#R-AccessRealTime">R-AccessRealTime</a>, 
          <a href="#R-PersistentIdentification">R-PersistentIdentification</a>,
          <a href="#R-QualityCompleteness">R-QualityCompleteness</a> and 
          <a href="#R-QualityMetrics">R-QualityMetrics</a>.</p>
      </section>

      <!-- Recife -->

      <section id="UC-RecifeOpenDataPortal" typeof="bibo:Chapter" resource="#UC-RecifeOpenDataPortal" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-RecifeOpenDataPortal">Recife Open Data Portal</h3>
        <p class="contributor">(Contributed by Bernadette Lóscio )<br />
          URL: <a href="http://dados.recife.pe.gov.br/">http://dados.recife.pe.gov.br/</a></p>
        <p>Recife is a city situated in the Northeast of Brazil and it is famous
          for being one of the Brazil’s biggest tech hubs. Recife is also one of
          the first Brazilian cities to release data generated by public sector
          organizations for public use as open data. Then <a href="http://dados.recife.pe.gov.br/">Open
            Data Portal Recife </a> was created to offer access to a repository
          of governmental machine-readable data about several domains,
          including: finances, health, education and tourism. Data is available
          in CSV and GeoJSON formats and every dataset has metadata
          that helps in the
          understanding and usage of the data. However, the metadata is not
          provided using standard vocabularies or taxonomies. In general, data
          is created in a static way, where data from relational databases are
          exported in a CSV format and then published in the data catalog.
          Currently, work is under way to dynamically generate data from
          relational databases so that data will be available as
          soon as it is created. The main phases of the development of this
          initiative were: to educate people with appropriate knowledge
          concerning open data, relevant data identification in order to
          identify the sources of data that their potential consumers could
          find useful, data extraction and transformation from the original data
          sources to open formats, configuration and installation of the
          open data catalog tool, data publication and portal release.</p>
        <p><strong>Elements:</strong></p>
        <ul>
          <li><b><i>Domains:</i></b> Base registers, cultural heritage
            information, geographic information, infrastructure information,
            social data and tourism information</li>
          <li><b><i>Obligation/motivation:</i></b> Data that must be provided to
            the public under a legal obligation (Brazilian Information Acess
            Act, edited in 2012); Provide public data to citizens.</li>
          <li><b><i>Usage:</i></b> Data that supports democracy and
            transparency; data used by application developers.</li>
          <li><b><i>Quality:</i></b> Verified and clean data.</li>
          <li><b><i>Size:</i></b> in general small to medium CSV files.</li>
          <li><b><i>Type/format:</i></b> CSV, GeoJson</li>
          <li><b><i>Rate of change:</i></b> different rates of change depending
            on the data source.</li>
          <li><b><i>Potential audience:</i></b> application developers,
            startups, government organizations.</li>
        </ul>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Use of common vocabularies to facilitate data integration.</li>
          <li>Provide structural metadata to help understanding and usage.</li>
          <li>Automate the data publishing process to keep data up to date and
            accurate.</li>
        </ul>
        <p> <strong>Requires:</strong> 
          <a href="#R-MetadataMachineRead">R-MetadataMachineRead</a>,
          <a href="#R-MetadataStandardized">R-MetadataStandardized</a>, 
          <a href="#R-MetadataDocum">R-MetadataDocum</a>, 
          <a href="#R-VocabReference">R-VocabReference</a>,
          <a href="#R-VocabDocum">R-VocabDocum</a>, 
          <a href="#R-VocabOpen">R-VocabOpen</a>,
          <a href="#R-SelectHighValue">R-SelectHighValue</a>, 
          <a href="#R-SelectDemand">R-SelectDemand</a>,
          <a href="#R-QualityCompleteness">R-QualityCompleteness</a>, 
          <a href="#R-SynchronizedData">R-SynchronizedData</a>
          and <a href="#R-QualityComparable">R-QualityComparable</a>.</p>
      </section>

      <!-- Dados Gov BR -->

      <section id="UC-DadosGovBr" typeof="bibo:Chapter" resource="#UC-DadosGovBr" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-DadosGovBr">Dados.gov.br</h3>
        <p class="contributor">(Contributed by Yasodara)<br />
          URL: <a href="http://dados.gov.br/">http://dados.gov.br/</a></p>
        <p> Dados.gov.br is the open data portal of Brazil's Federal
          Government. The site was built by a community network pulled together by
          three technicians from the Ministry of Planning. They managed the group
          from <a href="http://wiki.gtinda.ibge.gov.br/Tecnologia.ashx">INDA</a>
          or "National Infrastructure for Open Data." CKAN was chosen because it
          is free software and presents independent solutions for the placement
          of a data catalog of the Federal Government provided on the internet.</p>
        <p> <strong>Elements:</strong> </p>
        <ul>
          <li><b><i>Domains:</i></b> federal budget, addresses, Infrastructure
            information, e-gov tools usage, social data, geographic information,
            political information, Transport information.</li>
          <li><b><i>Obligation/motivation:</i></b> Data that must be provided to
            the public under a legal obligation, the called LAI or Brazilian
            Information Acess Act, edited in 2012.</li>
          <li><b><i>Usage: </i></b>Data that is the basis for services to the
            public; Data that has commercial reuse potential.</li>
          <li><b><i>Quality:</i></b> Authoritative, clean data, vetted and
            guaranteed.</li>
          <li><b><i>Lineage/Derivation:</i></b> Data came from various
            publishers. As a catalog, the site has faced several challenges, one
            of them was to integrate the various technologies and formulas used
            by publishers to provide datasets in the portal.</li>
          <li><b><i>Type/format:</i></b> Tabular data, text data.</li>
          <li><b><i>Rate of change:</i></b> There is fixed data and data with
            high rate of change.</li>
        </ul>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Data integration (lack of vocabularies).</li>
          <li>Collaborative construction of the portal: managing online sprints
            and balancing public expectatives.</li>
          <li>Licensing the data of the portal. Most of data that is in the
            portal does not have a special licence so there are types of license applied to different datasets.</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-FormatStandardized">R-FormatStandardized</a>,
          <a href="#R-VocabReference">R-VocabReference</a>, <a href="#R-LicenseAvailable">R-LicenseAvailable</a>
          and <a href="#R-QualityOpinions">R-QualityOpinions</a> </p>
      </section>

    <!-- ISOGEO Story -->

      <section id="UC-ISOGEOStory" typeof="bibo:Chapter" resource="#UC-ISOGEOStory"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-ISOGEOStory">ISO GEO Story</h3>
        <p class="contributor">(Contributed by Ghislain Atemezing)</p>
        <p> ISO GEO manages catalog records of geographic
          information in XML that conform to ISO-19139, a French
          adaptation of ISO-19115 (<a href="ISO-19139-Isogeo-set.zip">data sample</a>).
          They export thousands of records like that today but they need to
          manage them better. In their platform, they store the information in a
          more conventional manner and use this standard for export datasets
          compliant to the <a href="http://inspire.ec.europa.eu/">INSPIRE</a> 
          standards or via the <abbr title="Open geospatial Consortium">OGC</abbr>'s 
          <abbr title="Catalog Service for the Web">CSW</abbr> protocol.
          Sometimes, they have to enrich their metadata using tools like GeoSource 
          and accessed through an <abbr title="Spatial Data Infrastructure">SDI</abbr> 
          with their own metadata records. ISO GEO wants to be able to integrate all the different
          implementations of ISO-19139 in different tools in a single
          framework to better understand the thousands of metadata records they
          use in their day-to-day business. Types of information recorded in
          each file include: contact info (metadata) [data issued],
          spatial representation, reference system info [code space], spatial
          resolution, geographic extension of the data, file distribution, data
          quality and process step (<a href="http://www.eurecom.fr/%7Eatemezin/datalift/isogeo/5cb5cbeb-fiche1.xml">example</a>).</p>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Achieve interoperability between supporting applications, e.g.
            validation and discovery services built over a metadata repository.</li>
          <li>Capture the semantics of the current metadata records with respect
            to ISO-19139.</li>
          <li>A unified way to have access to each record within the catalog at
            different levels: local, regional, national or <abbr title="European Union">EU</abbr> level.</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-VocabReference">R-VocabReference</a>,
          <a href="#R-MetadataStandardized">R-MetadataStandardized</a> and <a href="#R-GranularityLevels">R-GranularityLevels</a>
        </p>
      </section>

      <!-- DUTCH Base registers -->

      <section id="UC-DutchBasicRegisters" rel="bibo:Chapter" resource="#h3_UC-DutchBasicRegisters" typeof="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-DutchBasicRegisters">Dutch Base Registers</h3>
        <p class="contributor">(Contributed by Christophe Guéret)<br />
          URL: <a href="http://www.e-overheid.nl/onderwerpen/stelselinformatiepunt/stelsel-van-basisregistraties">http://www.e-overheid.nl/onderwerpen/stelselinformatiepunt/stelsel-van-basisregistraties</a></p>
        <p> The Netherlands has a <a href="http://e-overheid.nl/onderwerpen/stelselinformatiepunt/stelsel-van-basisregistraties/basisregistraties">
          set of registers</a> that are under consideration for exposure as
          Linked (Open) Data in the context of the <a href="http://www.pilod.nl/wiki/Hoofdpagina">"PiLOD"</a> project.
          The registers contain information about
          buildings, people, businesses that other individual public bodies may
          want to refer to for they daily activities. One of them is, for
          instance, the service of public taxes ("BelastingDienst") which
          regularly pulls out data from several registers, stores this data in a
          big Oracle instance and curates it. This costly and time consuming
          process could be optimized by providing on-demand access to up-to-date
          descriptions provided by the register owners.</p>
        <p> <strong>Challenges:</strong> </p>
        In terms of challenges, linking is for once not much of an issue as <a

          href="http://www.e-overheid.nl/onderwerpen/stelselinformatiepunt/stelselthemas/verbindingen/verbindingen-tussen-basisregistraties">
          registers already cross-reference unique identifiers</a> (see also <a

          href="http://www.wikixl.nl/wiki/gemma/index.php/Ontsluiting_basisgegevens">
          http://www.wikixl.nl/wiki/gemma/index.php/Ontsluiting_basisgegevens</a>). 
        A <a href="http://www.pilod.nl/wiki/Boek/URI-strategie">URI scheme</a> 
        with predicable and persistent URIs is being considered for implementation. Actual
        challenges include:
        <ul>
          <li>Capacity: at this point, it is considered unreasonable to ask every register
            to publish its own data. Some of them export what
            they have on the national open data portal. This data has been used
            to do some testing with third-party publications from PiLOD project members but
            this is rather sensitive as a long term strategy (governmental data
            has to be tracable/trustable as such). The middle ground solution
            currently deployed is the PiLOD platform, a (semi)-official platform
            for publishing register data.</li>
          <li>Privacy: some of the register data is personal or may become so
            when linked to others (e.g. when addresses are used to disambiguate personal data). 
            Some registers will require secure access to
            some of their data to some people only (an example of non-open Linked Data). Some
            others can go along with open data as long as they get a precise log
            of who is using what.</li>
          <li>Revenue: institutions working under mixed government/non-government funding
            generate part of their revenue by selling some of the data they
            curate. Switching to an open data model will cause a direct loss
            in revenue that has to be compensated for by other means. This does not
            have to mean closing the data, e.g. a model of open dereferencing plus
            paid dumps can be considered, as well as other indirect revenue
            streams. </li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-VocabReference">R-VocabReference</a>,
          <a href="#R-SensitivePrivacy">R-SensitivePrivacy</a>, <a href="#R-UniqueIdentifier">R-UniqueIdentifier</a>,
          <a href="#R-PersistentIdentification">R-PersistentIdentification</a>,
          <a href="#R-MultipleRepresentations">R-MultipleRepresentations</a>,
          <a href="#R-CoreRegister">R-CoreRegister</a> and
          <a href="#R-DataUnavailabilityReference">R-DataUnavailabilityReference</a>.</p>
      </section>

    <!-- Wind Characterisation -->

      <section id="UC-WindCharacterizationScientificStudy" typeof="bibo:Chapter" resource="#UC-WindCharacterizationScientificStudy" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-WindCharacterizationScientificStudy">Wind Characterization Scientific Study</h3>
        <p class="contributor">(Contributed by Eric Stephan)</p>
        <p>This use case describes a data management facility being constructed
          to support scientific offshore wind energy research for the U.S.
          Department of Energy’s Office of Energy Efficiency and Renewable
          Energy (EERE) Wind and Water Power Program. The Reference Facility for
          Renewable Energy (RFORE) project is responsible for collecting wind
          characterization data from remote sensing and in-situ instruments
          located on an offshore platform. This raw data is collected by the
          Data Management Facility and processed into a standardized NetCDF
          format. Both the raw measurements and processed data are archived in
          the PNNL Institutional Computing (PIC) petascale computing facility.
          The DMF will record all processing history, quality assurance work,
          problem reporting, and maintenance activities for both instrumentation
          and data. All datasets, instrumentation, and activities are cataloged
          providing a seamless knowledge representation of the scientific study.
          The DMF catalog relies on linked open vocabularies and domain
          vocabularies to make the study data searchable. Scientists will be
          able to use the catalog for faceted browsing, ad-hoc searches, query
          by example. For accessing individual datasets a REST GET interface to
          the archive will be provided.</p>
        <p> <strong>Challenges:</strong><br />
        For accessing numerous datasets scientists will be accessing the archive
        directly using other protocols such as sftp, rsync, scp, and access
        techniques such as <a href="http://www.psc.edu/index.php/hpn-ssh">HPN-SSH</a>.</p>
        <p><strong>Requires:</strong> <a href="#R-FormatStandardized">R-FormatStandardized</a>,
          <a href="#R-VocabReference">R-VocabReference</a>, <a href="#R-VocabOpen">R-VocabOpen</a>
          and <a href="#R-AccessRealTime">R-AccessRealTime</a>.</p>
      </section>

    <!-- Digital Archiving -->

      <section id="UC-DigitalArchivingofLinkedData" typeof="bibo:Chapter" resource="#UC-DigitalArchivingofLinkedData" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-DigitalArchivingofLinkedData">Digital archiving of Linked Data</h3>
        <p class="contributor">(Contributed by Christophe Guéret)<br />
          URL: <a href="http://dans.knaw.nl/">http://dans.knaw.nl/</a></p>
        <p>Digital archives, such as <abbr title="Data Archiving and Networked Services"><a href="http://dans.knaw.nl/">DANS</a></abbr> 
          in the Netherlands, 
          have so far been concerned with the preservation of
          what could be defined as "frozen" datasets. A frozen dataset is a
          finished, self-contained set of data that does not evolve after it
          has been constituted. The goal of the preserving institution is to
          ensure this dataset remains available and readable for as many years
          as possible. This can for example concern an audio recording, a digitized
          image, e-books or database dumps. Consumers of the data are expected to 
          look for specific content based on its associated identifier, download 
          it from the archive and use it. Now comes
          the question of the preservation of Linked Open Data. In opposition to "frozen" data sets, linked
          data can be qualified as "live" data. The resources it contains are
          part of a larger entity to which third parties contribute, one of the
          design principles indicate that other data producers and consumers
          should be able to point to data. As <abbr title="Linked Data">LD</abbr> publishers stop offering their
          data (e.g. at the end of a project), taking the LD off-line as a dump
          and putting it in an archive effectively turns it into a frozen
          dataset, likewise SQL dumps and other kind of databases. The
          question then is to what extent this is an issue.</p>
        <p> <strong>Challenges:</strong> The archive has to think about whether
          dereferencing for resources found in preserved datasets is
          required or not, also to think about providing a SPARQL endpoint or not.
          If data consumers and publishers are fine with having RDF data dumps
          to be downloaded from the archive prior to its usage - just like any
          other digital item so far - the technical challenges could be limited
          to handling the size of the dumps and taking care of serialization
          evolution over time (e.g. from N-Triples to TriG, or from RDF/XML to <a

            href="http://www.rdfhdt.org/">HDT</a>) as the preference for these
          formats evolves. Turning a live dataset into a frozen dump also raises
          the question of the scope. Considering that LD items are only part of
          a much larger graph that gives them meaning through context the only
          valid dump would be a complete snapshot of the entire connected
          component of the Web of Data graph the target dataset is part of. </p>
        <p> <strong>Potential Requirements:</strong> Decide on the importance
          of the de-referencability of resources and the potential implications
          for domain names and naming of resources. Decide on the scope of the
          step that will turn a connected sub-graph into an isolated data dump.</p>
        <p> <strong>Requires:</strong> <a href="#R-VocabReference">R-VocabReference</a>,
          <a href="#R-UniqueIdentifier">R-UniqueIdentifier</a>, <a href="#R-PersistentIdentification">R-PersistentIdentification</a>
          <a href="#R-Archiving">R-Archiving</a> and <a href="#R-DataUnavailabilityReference">R-DataUnavailabilityReference</a>.</p>
      </section>

    <!-- LA Times Reporting -->

      <section id="UC-LATimesReporting" typeof="bibo:Chapter" resource="#UC-LATimesReporting" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-LATimesReporting">LA Times' Reporting of Ron Galperin's Infographic</h3>
        <p class="contributor">(Contributed by Phil Archer )<br />
          URL: <a href="http://articles.latimes.com/2014/mar/27/local/la-me-ln-gender-wage-gap-city-government-20140327">http://articles.latimes.com/2014/mar/27/local/la-me-ln-gender-wage-gap-city-government-20140327</a></p>
        <p> On 27 March 2014, the LA Times published a story <i>Women earn 83
            cents for every $1 men earn in L.A. city government</i>. It was
          based on an Infographic released by LA's City Controller, Ron
          Galperin. The Infographic was based on a dataset published on LA's
          open data portal, <a href="https://controllerdata.lacity.org/Payroll/Gender-Breakdown-of-City-Workers-by-Category/fvfi-5kja">
            Control Panel LA</a> . That portal uses the <a href="http://www.socrata.com/">Socrata</a>
          platform which offers a number of spreadhseet-like tools for examining
          the data, the ability to download it as CSV, embed it in a Web page
          and see its metadata.</p>
        <p> <strong>Positive aspects:</strong> </p>
        <ul>
          <li> The LA Times story makes its sources clear (it also links to a
            related <a href="http://www.pewsocialtrends.org/2013/12/11/on-pay-gap-millennial-women-near-parity-for-now/">
              Pew Research Center article</a> ). </li>
          <li>It offers readers a commentary on the particular issue raised and
            is easy for anyone to digest.</li>
          <li>Data sources are cited directly and can be followed up on by
            (human) readers.</li>
        </ul>
        <p> <strong>Negative aspects:</strong> </p>
        <ul>
          <li>The Infographic itself only cites the <a href="https://controllerdata.lacity.org/">data portal</a>, not the
            <a href="https://controllerdata.lacity.org/Payroll/Gender-Breakdown-of-City-Workers-by-Category/fvfi-5kja">specific dataset</a>.</li>
          <li> The <a href="https://controllerdata.lacity.org/Payroll/Gender-Breakdown-of-City-Workers-by-Category/fvfi-5kja/about">
              metadata</a> provided on the data portal is very sparse with many fields left empty. </li>
          <li>The dataset is itself the result of an analysis (there are only 8
            lines in the table), the raw data on which it is based is not cited,
            let alone made available, and the methods used are not described.</li>
        </ul>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Data Citation - how could Ron Galperin have referred to the source
            data in the Infographic? (the URI is way too long). QR code? Short
            PURL?</li>
          <li>How could the publisher of the data link to the Infographic as a
            visualization of it?</li>
          <li>In this case, the creator of the underlying data is the same as
            the creator of the Infographic, but if they were different, how
            could the data creator discover the Infographic, still less the
            media report about it?</li>
          <li>The methodology used is not explained - making it hard to assess
            trustworthiness. How can provenance be described?</li>
          <li>The metadata is incomplete and does not used a recognized standard
            vocabulary making automated discovery and use by anyone other than
            the data creator difficult.</li>
        </ul>
        <p> <strong>Other Data Journalism blogs:</strong> </p>
        <ul>
          <li> <a href="http://fivethirtyeight.com/features/what-the-fox-knows/">FiveThirtyEight</a></li>
          <li> <a href="http://blogs.wsj.com/numbersguy/">Wall Street Journal’s Number Guy column</a> </li>
          <li> <a href="http://www.theguardian.com/news/datablog"> Guardian’s data blog</a> </li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-MetadataStandardized">R-MetadataStandardized</a>,
          <a href="#R-UniqueIdentifier">R-UniqueIdentifier</a>, <a href="#R-Citable">R-Citable</a>
          and <a href="#R-DataMissingIncomplete">R-DataMissingIncomplete</a>. </p>
      </section>

    <!-- Uruguay -->

      <section id="UC-UruguayOpenDataCatalogue" typeof="bibo:Chapter" resource="#UC-UruguayOpenDataCatalogue" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-UruguayOpenDataCatalogue">Uruguay Open Data Catalog</h3>
        <p class="contributor">(Contributed by AGESIC )<br />
          URL: <a href="http://datauy.org/">http://datauy.org/</a></p>
        <p><a href="http://datauy.org/">Uruguay's open data portal</a> was launched in December 2012 and at the time of 
          writing holds 85 datasets containing 114 resources. The open data
          initiative prioritizes the “use of data” rather than “quantity of
          data”, that’s why the catalog also promotes a number of applications using data
          resources in some way (in common with many other data portals). 
          It’s important for the project to keep the
          ratio 1:3 between applications and datasets. Most of the resources
          are CSV and ESRI Shapefiles making this a catalog of 2 and 3 star resources according to the
          <a href="http://www.w3.org/DesignIssues/LinkedData">5 Stars of Linked Open Data</a> scheme.
          AGESIC does not have sufficient resources at government agencies to implement an
          open data liberation strategy and go to the next level. So when we are asked about opening
          data, keep it simple is the answer, and CSV is by far the easiest and
          smart way to start. Uruguay has an Access to public information law
          but doesn't have legislation about open data. The open data initiative
          is lead by AGESIC with the support of an open data working group drawn from
          multiple government agencies.</p>
        <p><strong>Elements:</strong></p>
        <ul>
          <li><b><i>Domains:</i></b>
            <ul>
              <li>Infrastructure: Most of the datasets are shapefiles</li>
              <li>Transportation: Shapefiles and CSV, containing information
                about public transportation (stops and frequency), roads,
                accidents, etc.</li>
              <li>Tourism: data about regional events, cultural agenda, hotels,
                camp sites, statistics</li>
              <li>Economics: budget, consumer price declarations, etc.</li>
              <li>Social development</li>
              <li>Environment</li>
              <li>Health</li>
              <li>Education</li>
              <li>Culture</li>
            </ul>
          </li>
          <li><b><i>Obligation/motivation:</i></b> There is no obligation for
            the government agencies to publish open data. All initiatives were
            carried on by agencies that want to support the initiative.</li>
          <li><b><i>Usage:</i></b> Develop applications and new services for
            citizens, agencies interoperability (exchange of information in open
            data formats), transparency.</li>
          <li><b><i>Quality:</i></b>Most of the data is realized properly, with complete or near complete metadata.</li>
          <li><b><i>Size:</i></b> Small; most of the datasets are less than 1Gb.</li>
          <li><b><i>Type/format:</i></b> At the time of writing: ESRI Shapefile (35), CSV (26), TXT (19), ZIP
            (12), HTML (7), XLS (6),PDF (4), XML (3), RAR (2)</li>
          <li><b><i>Rate of change:</i></b> Depends on the dataset.</li>
          <li><b><i>Data lifespan:</i></b> Depends on the dataset, some change
            in real time, other monthly, every 6 months, annual or static.</li>
          <li><b><i>Potential audience:</i></b> Developers, journalists, civil
            society, entrepreneurs.</li>
        </ul>
        <p> <strong>Challenges:</strong> Consolidation of tools to manage datasets,
          improve visualizations and transform resources to higher level (4 – 5
          stars). Automated publication process using harvesting or similar
          tools. Alerts or control panels to keep data updated. </p>
        <p> <strong>Requires:</strong> <a href="#R-VocabReference">R-VocabReference</a>
          <a href="#R-SynchronizedData">R-SynchronizedData</a>,
          <a href="#R-DataUnavailabilityReference">R-DataUnavailabilityReference</a> and
          <a href="R-DataMissingIncomplete">R-DataMissingIncomplete</a>.</p>
      </section>

    <!-- GS1 Digital -->

      <section id="UC-GS1-Digital" typeof="bibo:Chapter" resource="#UC-GS1-Digital" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-GS1-Digital">GS1 Digital</h3>
        <p class="contributor">(Contributed by Mark Harrison (University of
          Cambridge) &amp; Eric Kauz (GS1) )<br />
          URL: <a href="http://www.gs1.org/digital">http://www.gs1.org/digital</a></p>
        <p>Retailers and Manufacturers / Brand Owners are beginning to
          understand that there can be benefits to openly publishing structured
          data about products and product offerings on the Web as Linked Open
          Data. Some of the initial benefits may be enhanced search listing
          results (e.g. Google Rich Snippets) that improve the likelihood of
          consumers choosing such a product or product offer over an alternative
          product that lacks the enhanced search results. However, the longer
          term vision is that an ecosystem of new product-related services can
          be enabled if such data is available. Many of these will be
          consumer-facing and might be accessed via smartphones and other mobile
          devices, to help consumers to find the products and product offers
          that best match their search criteria and personal preferences or
          needs &mdash; and to alert them if a particular product is incompatible with
          their dietary preferences or other criteria such as ethical /
          environmental impact considerations &mdash; and to suggest an alternative
          product that may be a more suitable match. A more <a href="https://www.w3.org/2013/dwbp/wiki/Use_Cases#GS1:_GS1_Digital">complete
            description</a> of this use case is available.</p>
        <p><strong>Elements:</strong></p>
        <ul>
          <li><b><i>Domains:</i></b>
            <ul>
              <li>Product master data (e.g. technical specifications,
                ingredients, nutritional information, dimensions, weight,
                packaging).</li>
              <li>Product offerings (e.g. sales price, availability (online,
                locally), payment options, delivery/collection options.</li>
              <li>Ethical / environmental claims about a product and its
                production process.</li>
            </ul>
          </li>
          <li><b><i>Obligation/motivation:</i></b>
            <ul>
              <li>initially, enhanced search result listings (e.g. Google Rich
                Snippets);</li>
              <li>vision is to enable an ecosystem of new digital apps around
                product data;</li>
              <li>the food sector in the EU is already obliged under new food
                labelling legislation (EU 1169 / 2011, Article 14) to provide
                the same amount of information about a food product that is sold
                online to consumers as the information that would be available
                to them from the product packaging if they picked up the product
                in-store. Although the legislation does not suggest that Linked
                Open Data technology should be used to make the same information
                available in a machine-readable format, there is currently
                significant investment and effort to upgrade Web sites to provide
                accurate and detailed information about food products; the GS1
                Digital team consider that for a relatively small amount of
                effort, these companies could gain some tangible benefits (e.g.
                enhanced search results) from such compliance efforts by using
                Linked Open Data technology within their web pages.</li>
            </ul>
          </li>
          <li><b><i>Usage:</i></b>
            <ul>
              <li>data providing transparency about product characteristics</li>
              <li>data used to help consumers make informed choices about which
                products to buy/consume</li>
            </ul>
          </li>
          <li><b><i>Quality:</i></b> Very important to have trustworthy
            authoritative data from respective organizations.</li>
          <li><b><i>Size:</i></b> Typically 20+ factual claims per product -
            probably 40+ RDF triples.</li>
          <li><b><i>Type/format:</i></b> HTML + RDFa / JSON-LD / Microdata.</li>
          <li><b><i>Rate of change:</i></b> mostly static data initially &mdash; but
            subject to some variation over time</li>
          <li><b><i>Data lifespan:</i></b> data should remain accessible until
            products are no longer considered to be in circulation; this
            represents a challenge for deprecated product lines data that is
            stated authoritatively by one organization might be embedded /
            referenced in the data asserted by another organization; this raises
            concerns about whether embedded data becomes stale if it is
            inadequately synchronized, that referenced data is not dereferenced
            (and therefore not discovered / gathered) by consumers or the data.
            From a liability perspective, there also needs to be clarity about
            which organization asserted which factual information &mdash; and also
            information about which organization has the authority to assert
            specific factual claims.</li>
          <li><b><i>Potential audience:</i></b> machine-readable (search
            engines, data aggregators, mobile apps etc.)</li>
        </ul>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Linked Open Data about products is likely to be highly distributed
            in nature and various parties have authority over specific claims.</li>
          <li>Accreditation agencies have authority over ethical/environmental
            claims.</li>
          <li>Brand owners / manufacturers have authority over product master
            data.</li>
          <li>Retailers have authority over facts related to product offerings
            (price, availability etc.).</li>
          <li>An organization (e.g. retailer) might embed authoritative data
            asserted by another organization (e.g. brand owner) and there is the
            risk that such embedded information becomes stale if it is not
            continuously synchronized.</li>
          <li>An organization (e.g. retailer) might reference a graph of
            authoritative data that can be retrieved via an HTTP request to a
            remote HTTP URI. There is a risk that software or search engines
            consuming Linked Open Data containing such references may fail to
            dereference such HTTP URIs and in doing so may fail to gather all of
            the relevant data.</li>
          <li>Organizations are currently faced with a choice of whether to
            embed machine-readable structured data in their web pages using a
            block approach (e.g. using JSON-LD) or using an inline approach
            (e.g. using RDFa, RDFa Lite or Microdata). A block approach
            (JSON-LD) may be simpler and less brittle than inline annotation,
            especially as it can be easily decoupled from structural changes to
            the body of the web page that may happen over time in the redesign
            of a Web site. At present, tool support for the 3 major markup
            approaches for embedded Linked Open Data (RDFa, JSON-LD, Microdata)
            is unequal across the three formats and some tools may not export or
            import / ingest all 3 formats - some tools even fail to extract data
            from JSON-LD markup created by their corresponding export tool.
            There are some significant challenges to ensure that the structured
            data embedded within a web page is correctly linked to form coherent
            RDF triples, without any dangling nodes that should be connected to
            the Subject or other nodes.</li>
          <li>Only through the provision of best-in-class tool support that
            recognize all three major formats on a completely equal footing can
            organizations have any confidence that they can use any of the 3
            major markup formats and the ability to verify / validate that their
            own markup does result in the correct RDF triples.</li>
        </ul>
        <p> <strong>Potential Requirements:</strong> </p>
        <ul>
          <li>The ability to determine who asserted various facts &mdash; and whether
            they are the organization that can assert those facts
            authoritatively.</li>
          <li>Where data from other sources is embedded, there is a risk that
            the embedded data might be stale. It is therefore helpful to
            indicate which graph of triples is a snapshot in time from data from
            another source - and to provide a link to the original source, so
            that the consumer of the data has the opportunity to obtain a fresh
            version of the live data rather than relying on a potentially stale
            snapshot graph of data. <abbr title="Data on the Web Best Practices">DWBP</abbr> 
            could provide guidance about how to
            indicate which graph of data is a snapshot and where it came from.</li>
          <li>Consumers of Linked Open Data about products might rely on it for
            making decisions &mdash; not only about purchase but even consumption. If
            the data about a product is inaccurate or out-of-date, we might need
            to provide some guidance about how liability terms and disclaimers
            can be expressed in Linked Open Data. We’re not suggesting that we
            define such terms from a legal perspective, but perhaps there is an
            existing framework in a similar way that there is an existing
            framework for expressing various licences of the data? If not,
            perhaps such a framework needs to be developed - but outside of the
            DWBP group? Licensing generally says what you’re allowed to do with
            the data - but I don’t think it says anything about liability for
            using the data or making decisions based on that data. This area
            probably needs some clarification, particularly if there is a risk
            of injury or death (due to inaccurate information about allergens in
            a food product).</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-FormatStandardized">R-FormatStandardized</a>,
          <a href="#R-FormatMultiple">R-FormatMultiple</a>, <a href="#R-ProvAvailable">R-ProvAvailable</a>,
          <a href="#R-AccessUptodate">R-AccessUptodate</a>, <a href="#R-LicenseLiability">R-LicenseLiability</a>,
          <a href="#R-PersistentIdentification">R-PersistentIdentification</a>,
          <a href="#R-Citable">R-Citable</a>, <a href="#R-SynchronizedData">R-SynchronizedData</a>
          and <a href="#R-CoreRegister">R-CoreRegister</a>.</p>
      </section>

    <!-- Tabulae -->

      <section id="UC-Tabulae" typeof="bibo:Chapter" resource="#UC-Tabulae" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-Tabulae">Tabulae - how to get value out of data</h3>
        <p class="contributor">(Contributed by Luis Polo )<br />
          URL: <a href="http://www.tabulaeapp.com/">http://www.tabulaeapp.com/</a></p>
        <p>Tabul.ae is a framework to publish and visually explore data that can
          used to deploy powerful and easy-to-exploit open data platforms, so
          allowing organizations to unleash the potential of their data. The
          aim is to enable data owners (public organizations) and consumers
          (citizens and business reusers) to transform the information they
          manage into added-value knowledge, empowering them to easily create
          data-centric Web applications. These applications are built upon
          interactive and powerful graphs, and take the shape of interactive
          charts, dashboards, infographics and reports. Tabulae provides a high
          degree of assistance to create these apps and also automate several
          data visualization tasks (e.g. recognition of geographical entities
          to automatically generate a map). In addition, the charts and maps are
          portable outside the platform and can be smartly integrated with any
          web content, enhancing the reusability of the information.</p>
        <p> <strong>Elements:</strong> </p>
        <ul>
          <li><b><i>Domains:</i></b> Quantitative and geographical information:
            stats, biodiversity, socio-economic indicators, environment,
            security, etc.</li>
          <li><b><i>Obligation/motivation:</i></b> to help citizens and
            companies (especially, consultancy firms) to understand and create
            value from open data by means of reusable, user-made visualizations.</li>
          <li><b><i>Usage:</i></b> Data used by citizens, public employees and
            companies.</li>
          <li><b><i>Quality:</i></b> The information must be at least
            semi-structured (for instance, an spreadsheet).</li>
          <li><b><i>Size:</i></b> Medium and large datasets (hundreds of
            thousands and millions rows).</li>
          <li><b><i>Type/format:</i></b> Tabulae can manage relational
            databases, GeoJSON, CSV files and spreadsheets, and provides an API
            for programmatic access.</li>
          <li><b><i>Rate of change:</i></b> depending on the original datasets.
            The platform enables automatic update from original sources.</li>
          <li><b><i>Data lifespan:</i></b> depending on the original datasets.</li>
          <li><b><i>Potential audience:</i></b> Organizations that want to
            publish their catalogue of datasets and aim to maximize their impact
            and consumption.</li>
        </ul>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Quality of data and metadata.</li>
          <li>Inconsistency between different data sources.</li>
          <li>Wide variety of formats and technologies.</li>
          <li>Different data schemas that complicates the integration of data
            sources.</li>
          <li>Diversity and (sometimes) complexity of Licenses.</li>
          <li>Data persistence.</li>
          <li>Internationalization and format issues (e.g., languages, numbers,
            dates, etc.)</li>
        </ul>
        <p> <strong>Potential Requirements:</strong> </p>
        <ul>
          <li>Dataset versioning and updating mechanisms.</li>
          <li>Standardization of schemas.</li>
          <li>Integration with other platforms/services.</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-FormatStandardized">R-FormatStandardized</a>,
          <a href="#R-FormatLocalize">R-FormatLocalize</a>, <a href="#R-VocabReference">R-VocabReference</a>,
          <a href="#R-VocabVersion">R-VocabVersion</a>, <a href="#R-ProvAvailable">R-ProvAvailable</a>,
          <a href="#R-SynchronizedData">R-SynchronizedData</a> and <a href="#R-QualityCompleteness">R-QualityCompleteness</a>.</p>
      </section>

     <!-- Violence map -->

      <section id="UC-ViolenceMap" typeof="bibo:Chapter" resource="#UC-ViolenceMap" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-ViolenceMap">Retrato da Violência (Violence Map)</h3>
        <p class="contributor">(Contributed by Yasodara )<br />
          URL: <a href="https://github.com/dataviz/retrato-da-violencia.org">https://github.com/dataviz/retrato-da-violencia.org</a></p>
        <p> This is a Data Visualization made in 2012 by <a href="http://vitorbaptista.com/">Vitor
            Batista</a> , <a href="http://leotartari.com/">Léo tartari</a> and
          <a href="http://tbueno.com/">Thiago Bueno</a> for a <abbr title="World Wide Web Consortium">W3C</abbr>
          Brazil Office challenge about data from Rio Grande do Sul (a brazilian
          region). The data was released in a .zip package, the original format
          was .csv. The code and the documentation of the project are <a href="https://github.com/dataviz/retrato-da-violencia.org">
            in it's GitHub repository</a> </p>
        <p> <strong>Elements:</strong> </p>
        <ul>
          <li><b><i>Domains:</i></b> political information, regional security
            information.</li>
          <li><b><i>Obligation/motivation:</i></b> Data that must be provided to
            the public under a legal obligation, the LAI or Brazilian
            Information Acess Act, edited in 2012.</li>
          <li><b><i>Quality:</i></b> not guaranteed.</li>
          <li><b><i>Type/format:</i></b> Tabular data.</li>
          <li><b><i>Rate of change:</i></b> There is no new releases of the data, this was a one-off</li>
        </ul>
        <p> <strong>Positive Aspects:</strong> the decision to transform the CSV
          in to JSON was based on the necessity to have hierarchical data. The
          ability to map the CSV structure to XML or JSON was
          considered as a positive since JSON can cover more
          complex structures. </p>
        <p> <strong>Negative Aspects:</strong> the data is already outdated (in 2014), there is no provision for new releases, and
          there's no associated metadata.</p>
        <p> <strong>Requires:</strong> <a href="#R-QualityCompleteness">R-QualityCompleteness</a>,
          <a href="#R-AcessUptodate">R-AcessUptodate</a>, <a href="#R-MetadataAvailable">R-MetadataAvailable</a>,
          <a href="#R-PersistentIdentification">R-PersistentIdentification</a>,
          <a href="#R-SynchronizedData">R-SynchronizedData</a> and <a href="#R-SensitiveSecurity">R-SensitiveSecurity</a>.</p>
      </section>

    <!-- Bio2RDF -->

      <section id="UC-Bio2RDF" typeof="bibo:Chapter" resource="#UC-Bio2RDF" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-Bio2RDF">Bio2RDF</h3>
        <p class="contributor">(Contributed by Carlos Laufer)<br />
          URL: <a href="http://bio2rdf.org/">http://bio2rdf.org/</a></p>
        <p> <a href="http://bio2rdf.org/">Bio2RDF</a><sup><a href="#bio1">1</a></sup> is an open source project
          that uses Semantic Web technologies to make possible the distributed
          querying of integrated life sciences data. Since its inception<sup><a href="#bio2">2</a></sup>,
          Bio2RDF has made use of the Resource Description Framework (RDF) and
          the RDF Schema (RDFS) to unify the representation of data obtained
          from diverse fields (molecules, enzymes, pathways, diseases, etc.) and
          heterogeneously formatted biological data (e.g. flat-files,
          tab-delimited files, SQL, dataset specific formats, XML etc.). Once
          converted to RDF, this biological data can be queried using the SPARQL
          Protocol and RDF Query Language (SPARQL), which can be used to
          federate queries across multiple SPARQL endpoints. </p>
        <p> <strong>Elements:</strong> </p>
        <ul>
          <li><b><i>Domains:</i></b>Biological data </li>
          <li><b><i>Obligation/motivation:</i></b> Biological researchers are
            often confronted with the inevitable and unenviable task of having
            to integrate their experimental results with those of others. This
            task usually involves a tedious manual search and assimilation of
            often isolated and diverse collections of life sciences data hosted
            by multiple independent providers including organizations such as
            the National Center for Bio-technology Information (<a href="http://www.ncbi.nlm.nih.gov/">NCBI</a>) 
            and the European Bioinformatics Institute (<a href="http://www.ebi.ac.uk/">EBI</a>) 
            that provide dozens of user-submitted and curated datasets, as well
            as smaller institutions such as the Donaldson group that publishes
            <a href="http://irefindex.org/">iRefIndex</a><sup><a href="#bio3">3</a></sup>, 
            a database of molecular interactions aggregated from
            13 data sources. While these mostly isolated silos of biological
            information occasionally provide links between their records (e.g.
            <a href="http://www.uniprot.org">UniProt</a> links its entries to hundreds of other datasets), 
            they are typically serialized in either HTML elements or in flat file
            data dumps that lack the semantic richness required to serialize the
            intent of the linkage between data records. With thousands of
            biological databases and hundreds of thousands of
            datasets, the ability to find relevant data is hampered by
            non-standard database interfaces and an enormous number of haphazard
            data formats<sup><a href="#bio4">4</a></sup>. Moreover, metadata about these biological data
            providers (dataset source data information, dataset versioning,
            licensing information, date of creation, etc.) is often difficult to
            obtain. Taken together, the inability to easily navigate through
            available data presents an overwhelming barrier to their reuse. </li>
          <li><b><i>Usage:</i></b> Biological research</li>
          <li><b><i>Quality:</i></b> Bio2RDF scripts generate
            provenance records using the <abbr title="World Wide Web Consortium">W3C</abbr>
            Vocabulary of Interlinked Datasets (<a href="http://www.w3.org/TR/void/">VoID</a>), 
            the Provenance vocabulary
            (<a href="http://www.w3.org/TR/prov-overview/">PROV</a>) and <a href="http://dublincore.org/">Dublin Core</a> 
            vocabulary. Each data item is linked to a
            provenance object that indicates the source of the data, the time at
            which the RDF was generated, licensing (if available from the data
            source provider), the SPARQL endpoint in which the resource can be
            found, and the downloadable RDF file where the data item is located.
            Each dataset provenance object has a unique IRI and label based on
            the dataset name and creation date. The date-specific dataset IRI is
            linked to a unique dataset IRI using the 
            PROV predicate <code>wasDerivedFrom</code> such that one can query the dataset
            SPARQL endpoint to retrieve all provenance records for datasets
            created on different dates. Each resource in the dataset is linked
            the date-unique dataset IRI that is part of the provenance record
            using the VoID <code>inDataset</code> predicate. Other important features of
            the provenance record include the use of the Dublin Core <code>creator</code>
            term to link a dataset to the script on Github that was used to
            generate it, the VoID predicate <code>sparqlEndpoint</code> to point to the
            dataset SPARQL endpoint, and VoID predicate <code>dataDump</code> to point to
            the data download URL.
            <p>Dataset metrics </p>
            <ol>
              <li>total number of triples </li>
              <li>number of unique subjects </li>
              <li>number of unique predicates </li>
              <li>number of unique objects </li>
              <li>number of unique types </li>
              <li>unique predicate-object links and their frequencies </li>
              <li>unique predicate-literal links and their frequencies </li>
              <li>unique subject type-predicate-object type links and their
                frequencies </li>
              <li>unique subject type-predicate-literal links and their
                frequencies </li>
              <li>total number of references to a namespace </li>
              <li>total number of inter-namespace references </li>
              <li>total number of inter-namespace-predicate references </li>
            </ol>
          </li>
          <li><b><i>Size:</i></b> At the time of writing, thirty five datasets
          have been generated as part of the <a href="http://download.bio2rdf.org/release/3/release.html">Bio2RDF 3 release</a>. 
          Several of the datasets
          are themselves collections of datasets that are now available as one
          resource. Each dataset has been loaded into a dataset-specific SPARQL
          endpoint using Openlink Virtuoso. All updated Bio2RDF linked data and
          their corresponding Virtuoso DB files are available for <a href="http://download.bio2rdf.org/current/release.html">download</a>.</li>
        </ul>
        <ul>
          <li>Type/format: RDF </li>
          <li>Rate of change: depends on data source</li>
          <li>Data lifespan: depends on data source</li>
          <li>Potential audience: Biological researchers</li>
        </ul>
        <p><strong>References:</strong></p>
        <ol>
          <li id="bio1">Callahan A, Cruz-Toledo J, Ansell P, Klassen D, Tumarello G,
            Dumontier M: <a href="http://ceur-ws.org/Vol-952/paper_18.pdf">Improved dataset coverage and interoperability with
            Bio2RDF Release 2</a> (PDF). SWAT4LS 2012, Proceedings of the 5th
            International Workshop on Semantic Web Applications and Tools for
            Life Sciences, Paris, France, November 28-30, 2012.</li>
          <li id="bio2">Belleau F, Nolin MA, Tourigny N, Rigault P, Morissette J: Bio2RDF:
            towards a mashup to build bioinformatics knowledge systems. J Biomed
            Inform 2008, 41(5):706-716.</li>
          <li id="bio3">Razick S, Magklaras G, Donaldson IM: iRefIndex: a consolidated
            protein interaction database with provenance. BMC Bioinformatics
            2008, 9:405.</li>
          <li id="bio4">Goble C, Stevens R: State of the nation in data integration for
            bioinformatics. J Biomed Inform 2008, 41(5):687-693.</li>
        </ol>
        <p><strong>Challenges:</strong></p>
        <ul>
          <li>Lack of human-readable metadata. </li>
          <li>Data variability (models, sources, etc.). </li>
          <li> RDFizations of Datasets. </li>
          <li> Wide variety of formats and technologies. </li>
        </ul>
        <p><strong>Potential Requirements:</strong></p>
        <ul>
          <li>Dataset versioning and updating mechanisms </li>
          <li>Standardization of schemas </li>
          <li>Integration with other platforms/services </li>
          <li>Data persistence </li>
        </ul>
        <p><strong>Requires:</strong> <a href="#R-Archiving"> R-Archiving </a>, <a href="#R-VocabReference">R-VocabReference</a>,
            <a href="#R-FormatMultiple">R-FormatMultiple</a>, <a href="#R-AccessUptodate">R-AccessUptodate</a>,
            <a href="#R-PersistentIdentification">R-PersistentIdentification</a>,
            <a href="#R-FormatStandardized">R-FormatStandardized </a>,
            <a href="#R-DataUnavailabilityReference">R-DataUnavailabilityReference</a> and
            <a href="#R-DataLifecyclePrivacy">R-DataLifecyclePrivacy</a>.</p>
      </section>

      <!-- Documented Support / release -->

      <section id="UC-DocumentedSupportandRelease" typeof="bibo:Chapter" resource="#UC-DocumentedSupportandRelease" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-DocumentedSupportandRelease">Documented Support and Release of Data</h3>
        <p class="contributor">(Contributed by Deirdre Lee)</p>
        <p>While many cases of data on the Web may contain metadata about
          creation data and last update, the regularity of the release schedule
          is not always clear. Similarly, how and by whom the dataset is
          supported should also be made clear in the metadata. These attributes
          are necessary to improve the reliability of the data so that
          third-party users can trust the timely delivery of the data, with a
          follow-up point should there be any issues.</p>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Release schedule of data is often unknown.</li>
          <li>Support mechanisms (e.g. contact point) of data is often unknown.</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-AccessUptodate">R-AccessUptodate</a>
          and <a href="#R-SLAAvailable">R-SLAAvailable</a> </p>
      </section>

    <!-- Feedback loop -->

      <section id="UC-FeedbackLoopforCorrections" typeof="bibo:Chapter" resource="#UC-FeedbackLoopforCorrections" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-FeedbackLoopforCorrections">Feedback Loop for Corrections</h3>
        <p class="contributor">(Contributed by Deirdre Lee based on work by Pieter Colpaert)</p>
        <p>One of the advantages of publishing Open Data is often quoted as
          improving the quality of the data. Many eyes looking at a dataset
          helps spot errors and holes quicker than a public body may identify
          this themselves. For example, in his paper <a href="http://link.springer.com/chapter/10.1007%2F978-3-319-07443-6_56">Route
            planning using Linked Open Data</a> Colpaert looks at how feedback
          can be incorporated into transport data to improve its data quality.
          How can this 'improved' data be fed back into the public
          body, processed an incorporated into the original dataset? Should there
          be an automated mechanism for this? How can the improvement be
          described in a machine readable format? What is best practice for
          reincorporating such improvements?</p>
        <p> <strong>Technical Challenges:</strong> </p>
        <ul>
          <li>Should there be an automated mechanism for this?</li>
          <li>How can the improvement be described in a machine readable format?</li>
          <li>What is best practice for reincorporating such improvements?</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-QualityOpinions">R-QualityOpinions</a>
          and <a href="#R-IncorporateFeedback">R-IncorporateFeedback</a> </p>
      </section>

      <!-- natural disasters -->

      <section id="UC-DatasetsforNaturalHazardsManagement" typeof="bibo:Chapter" resource="#UC-DatasetsforNaturalHazardsManagement" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-DatasetsforNaturalHazardsManagement">Datasets required for Natural Hazards Management</h3>
        <p class="contributor">(Contributed by Deirdre Lee based on Prof
          Vassilis Vescoukis' talk at the <abbr title="Open Knowledge Foundation">OKF</abbr> Greece workshop)<br />
          URL: <a href="http://okfn.gr/2014/03/okf-meetup/">http://okfn.gr/2014/03/okf-meetup/</a></p>
        <p>Many of the datasets that are required for Natural Hazards
          Management, for example critical infrastructure, utility services,
          road networks, are not available online as they are also deemed to be
          datasets that could be used for homeland security attacks. </p>
        <p><strong>Requires:</strong> <a href="#R-SensitiveSecurity">SensitiveSecurity</a>.</p>
      </section>

      <!-- OKFN Transport -->

      <section id="UC-OKFNTransportWG" typeof="bibo:Chapter" resource="#ref" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-OKFNTransportWG">OKFN Transport WG</h3>
        <p class="contributor">(Contributed by Deirdre Lee based on the 
          <a href="http://www.scribd.com/doc/111890372/Helsinki-Open-Transport-Data-Manifesto">2012 ePSI Open Transport Data Manifesto</a>)</p>
        <p>The Context: Transportation is an important contemporary issue that
          has a direct impact on economic strength, environmental sustainability
          and social equity. Accordingly, transport data &mdash; largely produced or
          gathered by public sector organisations or semi-private entites, quite
          often locally &mdash; represents one of the most valuable sources of public
          sector information (PSI, also called ‘open data’), a key policy area
          for many, including the European Commission.</p>
        <p>The Challenge: Combined with the advancement of Web technologies
          and the increasing use of smart phones, the demand for high quality
          machine-readable and openly licensed transport data, allowing for
          reuse in commercial and non-commercial products and services, is
          rising rapidly. Unfortunately this demand is not met by current
          supply: many transport data producers and holders (from the public and
          private sectors) have not managed to respond adequately to these new
          challenges set by society and technology.</p>
        <p>So what do we need?</p>
        <ul>
          <li>Access to any transport data of any operator, of high quality, in
            real time, against free or at least fair standard conditions.</li>
          <li>An inclusive infrastructure, based on common open,
            non-discriminatory and interoperable standards and APIs, to which
            operators, service providers, developers and users can connect.</li>
          <li>An ecosystem wherein universal access and re-usabiliy of transport
            data is the rule, not the exception.</li>
        </ul>
        <p>Why is this not happening?</p>
        <ul>
          <li>Data that is necessary for integrated personal transportation
            solutions is rich and encompasses several domains (geospatial data,
            environmental data, private service provider data), involving a wide
            array of data holders from the public and private sectors. Because
            of its very nature, transport data is often held locally.</li>
          <li>Legacies create lock-ins that prevent adoption of open standards
            and hamper interoperability. </li>
          <li>Many operators and incumbent service providers, in particular
            those relying on income from sales of data, still regard selective
            and exclusive access to transport data as a competitive advantage,
            restricting access and reuse through the exercise of intellectual
            property rights.</li>
          <li>Perceived liability risks, often associated with data quality
            issues, prevent operators from opening up their data.</li>
          <li>Significant differences between countries, regions and transport
            modalities in terms of level of development, market maturity and
            associated business models prevent a ‘one size fits all’ solution.</li>
          <li>A lack of leadership in the value chain, either by the industry or
            from the authorities (whatever the level), limits governance
            capabilities as to establishment of access, accessibility and other
            framework conditions, creating a need for a subtle mix of mostly
            bottom-up instruments and a dash of top-down measures.</li>
          <li>Existing market players with associated interests turn
            governmental actions into a delicate matter, in particular as to the
            question of where the role of the government should start and end
            within the value chain and where the market parties should take over
            and become the driving factor.</li>
          <li>Where market parties need to step in, the lack of a clear and
            predictable environment prevents businesses from establishing a
            long-term perspective, whereby fair competition needs to be
            safeguarded.</li>
        </ul>
        <p><strong>Requires:</strong> <a href="#R-AccessBulk">R-AccessBulk</a>,
          <a href="#R-FormatOpen">R-FormatOpen</a>, <a href="#R-VocabOpen">R-VocabOpen</a>,
          <a href="#R-QualityMetrics">R-QualityMetrics</a>, <a href="#R-FormatLocalize">R-FormatLocalize</a>,
          <a href="#R-LicenseLiability">R-LicenseLiability</a>,
          <a href="#R-DataUnavailabilityReference">R-DataUnavailabilityReference</a> and
          <a href="#R-DataMissingIncomplete">R-DataMissingIncomplete</a>.</p>
      </section>

      <!-- Tracking -->

      <section id="UC-TrackingofDataUsage" typeof="bibo:Chapter" resource="#UC-TrackingofDataUsage" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-TrackingofDataUsage">Tracking of Data Usage</h3>
        <p class="contributor">(Contributed by Deirdre Lee &amp; Phil Archer)</p>
        <p>There are many potential/perceived benefits of <a href="http://opendefinition.org/">Open
            Data</a>, however in order to publish data, some initial
          investment/resources are required by public bodies. When justifying
          these resources and evaluating the impact of the investment, many open
          data providers express the desire to be able to track how the datasets
          are being used. However open data by design often requires no
          registration, explanation or feedback to enable the access to and
          usage of the data. How can data usage be tracked in order to inform
          the Open Data ecosystem and improve data provision?</p>

        <p>An example of this is the UK Mapping Agency, Ordnance Survey. Under an agreement with 
        the UK government, the Ordnance Survey has published a lot of its mapping data as 
        <a href="http://www.ordnancesurvey.co.uk/business-and-government/products/opendata-products.html">open data</a>, 
        including some pioneering work in <a href="http://data.ordnancesurvey.co.uk/">Linked Geospatial Data</a>. 
        Doing this has required significant effort and public investment, as has the effort 
        to include semantics in the European Union's <a href="http://inspire.ec.europa.eu/">INSPIRE</a> data model. In common with just about 
        all organizations, public and private, investment in such an activity requires justification and 
        so, speaking at the Linking Geospatial Data workshop in March 2014, the Ordnance Survey's 
        Peter Parslow <a href="http://www.w3.org/2014/03/lgd/report#useitorloseit">said</a> that maintaining the service depends on showing that it is being used. 
        <p>Server logs only tell you so much, i.e. the number of requests, but they 
        don't show you the quality of the usage, or what the data is being used for. A small 
        number of high quality, high impact uses of the data might very well have more 
        significance than a large number of low quality ones.</p>
        <p>Such a desire to know more about what data is being used for is not unique to Ordnance Survey. 
        For example, the equivalent body in Denmark, the <a href="http://eng.gst.dk/">Danish Geodata Agency</a>, 
        offers all its data for free but requires you to register and give information about your 
        intended use. Even where data is provided for free, the provider is very likely to want 
        some recognition for their efforts as an encouragement to keep providing it, often in 
        the face of demands for justification from line managers.</p>
        <p>At the same time, users of the data need an incentive, other than simple 
        politeness, to recognize the efforts made by data providers. Therefore any vocabulary that 
        describes the use made of a dataset must also help in the discovery of that usage, 
        i.e. in the discovery of the user's own work. Usage in this context means anything from 
        usage within an application to citation in academic research.</p>

        <p><strong>Elements</strong></p><ul>
          <li>Policy framework including:<ul><li>sustainability;</li><li>impact assessment;</li><li>return on investment.</li></ul></li></ul>

        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>No registration required by data user.</li>
          <li>Automatic vs. manual solution.</li>
          <li>Solution should not break basic open data principles.</li>
          <li>Many developers will not mind giving feedback if it will improve quality of data/service.</li>
          <li>Assessing use of data without restricting or disincentivizing such use.</li>
          <li>Incentivizing provision of data about usage.</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-TrackDataUsage">R-TrackDataUsage</a>.</p>
      </section>

    <!-- Open City Pipeline -->

      <section id="UC-OpenCityDataPipeline" typeof="bibo:Chapter" resource="#UC-OpenCityDataPipeline" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-OpenCityDataPipeline">Open City Data Pipeline</h3>
        <p class="contributor">(Contributed by Deirdre Lee, based on a 
          <a href="https://ai.wu.ac.at/%7Epolleres/presentations/20140319CityDataPipeline_EDF2014_Polleres.pdf">presentation 
          by Axel Polleres</a> at <a href="http://2014.data-forum.eu/"><abbr title="European Data Forum">EDF</abbr> 2014</a>).</p>
        <p>The Open City Data Pipeline aims to to provide an extensible platform
          to support citizens and city administrators by providing city key
          performance indicators (KPIs), leveraging open data sources. The
          assumption of open data is that “Added value comes from comparable open
          datasets being combined.” Open data needs stronger standards to be
          useful, in particular for industrial uptake. Industrial usage has
          different requirements than app hobbyist or civil society, it's
          important to think how open data can be used by industry at the time of
          publication. They have developed a data pipeline to:</p>
        <ol>
          <li>(semi-)automatically collect and integrate various open data sources in different formats;</li>
          <li>compose and calculate complex city KPIs from the collected data.</li>
        </ol>
        <p>Current Data Summary</p>
        <ul>
          <li>Ca. 475 different indicators </li>
          <li>Categories: Demography, Geography, Social Aspects, Economy,
            Environment, etc. </li>
          <li>from 32 sources (html, CSV, RDF &hellip;) </li>
          <li>Wikipedia, urbanaudit.org, Statistics from City homepages, country Statistics, iea.org.</li>
          <li>Covering 350+cities in 28 European countries.</li>
          <li>District data for selected cities (Vienna, Berlin).</li>
          <li>Mostly snapshots, partially covering timelines.</li>
          <li>On average ca. 285 facts per city.</li>
        </ul>
        <p>Base assumption (for our use case): Added value comes from comparable
          open datasets being combined</p>
        <p>Challenges &amp; Lessons Learnt:</p>
        <ul>
          <li> <b>Incomplete</b> Data: can be partially overcome by:
            <ul>
              <li>ontological reasoning (RDF &amp; OWL), by aggregation, or
                by rules &amp; equations, e.g. <code>:populationDensity = :population/:area</code>;</li>
              <li>By statistical methods or Multi-dimensional Matrix
                Decomposition (unfortunately only partially successful, because
                these algorithms assume normally-distributed data).</li>
            </ul>
          </li>
          <li><b>Incomparable</b> data:
            <ul>
              <li><code>dbpedia:populationTotal</code></li>
              <li><code>dbpedia:populationCensus</code></li>
            </ul>
          </li>
          <li><b>Heterogeneity</b> across open government data efforts:
            <ul>
              <li>different <b>indicators</b>, different temporal and spatial granularity;</li>
              <li>different <b>licenses</b> of open data: e.g. CC-BY, country specific licences, etc. </li>
              <li>Heterogeneous <b>formats</b> and heterogeneity within formats, especially CSV.</li>
            </ul>
          </li>
        </ul>
        <p><strong>Challenges:</strong></p>
        <ul>
          <li>Incomplete data (can be overcome using semantic technologies
            and/or statistical methods).</li>
          <li>Heterogeneity (indicators, licenses, formats).</li>
          <li>Open data needs stronger standards to be useful (in particular for
            industrial uptake), at a metadata level, and dataset level.</li>
          <li>Metadata is not always uniform, not only titles of columns, but
            standardization about units, etc.</li>
        </ul>
        <p><strong>Requires:</strong> <a href="#R-FormatStandardized">R-FormatStandardized</a>,
          <a href="#R-IndustryReuse">R-IndustryReuse</a>, <a href="#R-QualityCompleteness">R-QualityCompleteness</a>
          and <a href="#R-QualityComparable">R-QualityComparable</a>.</p>
      </section>

      <!-- Machine readable licences -->

      <section id="UC-MachineReadabilityandInteroperabilityofLicenses" typeof="bibo:Chapter" resource="#UC-MachineReadabilityandInteroperabilityofLicenses" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-MachineReadabilityandInteroperabilityofLicenses">Machine-readability and Interoperability of Licenses</h3>
        <p class="contributor">(Contributed by Deirdre Lee, based on 
          <a href="http://lists.w3.org/Archives/Public/public-dwbp-wg/2014Mar/0189.html">post by Leigh Dodds</a>)</p>
        <p> There are many different <a href="http://opendefinition.org/licenses/">licenses</a> 
          available under which data can be published on the Web, e.g.
            <a href="http://creativecommons.org/">Creative Commons</a>, 
          <a href="http://opendatacommons.org/">Open Data Commons</a>, national licenses, etc. It
          is important that the license is available in a machine-readable
          format. Leigh Dodds has done some work towards this with the <a href="http://schema.theodi.org/odrs/">Open Data
          Rights Statement Vocabulary</a> including guides for 
          <a href="http://theodi.org/guides/publishers-guide-to-the-open-data-rights-statement-vocabulary">publishers</a> 
          and <a href="http://theodi.org/guides/odrs-reusers-guide">reusers</a>. 
          Another issue is when data under different licenses are combined, the license terms under which
          the data is available also have to be merged. This interoperability of
          licenses is a challenge.</p>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Standard vocabulary for data licenses.</li>
          <li>Machine-readability of data licenses.</li>
          <li>Interoperability of data licenses.</li>
        </ul>
        <p><strong>Requires:</strong> <a href="#R-LicenseAvailable">R-LicenseAvailable</a></p>
        <p><strong>NB</strong> there is also a requirement for licenses to be interoperable but this 
        is out of scope as defined by the Working Group's <a href="http://www.w3.org/2013/05/odbp-charter#noscope">charter</a>.</p>
      </section>
      <section id="UC-MachineReadabilityofSLAs" typeof="bibo:Chapter" resource="#UC-MachineReadabilityofSLAs" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-MachineReadabilityofSLAs">Machine-readability of SLAs</h3>
        <p class="contributor">(Contributed by Deirdre Lee based on a number of
          talks at <a href="http://2014.data-forum.eu/program"><abbr title="European Data Forum">EDF</abbr> 2014</a>)</p>
        <p>A main focus of publishing data on the Web is to facilitate industry
          resuse for commercial purposes. In order for a commercial body to
          reuse data, the terms of reuse must be clear. The legal
          terms of reuse are included in the license, but there are other
          factors that are important for commercial reuse, e.g. reliabiliy,
          support, incident recovery, etc. These could be included in an Service Level Agreement (SLA).</p>
        <p><strong>Challenges:</strong></p>
        <ul>
          <li>Defining common SLA requrirements for industry reuse.</li>
          <li>Existing standards/vocabularies for SLA requirements.</li>
          <li>Machine-readable access to SLAs.</li>
        </ul>
        <p><strong>Requires:</strong><a href="#R-SLAAvailable">R-SLAAvailable</a>.</p>
      </section>

    <!-- data APIs -->

      <section id="UC-PublicationofDataviaAPIs" typeof="bibo:Chapter" resource="#UC-PublicationofDataviaAPIs" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-PublicationofDataviaAPIs">Publication of Data via APIs</h3>
        <p class="contributor">(Contributed by Deirdre Lee)</p>
        <p> APIs are commonly used to publish data in formats designed for
          machine-consumption, as opposed to the corresponding HTML pages whose
          main aim is to deliver content suitable for human-consumption. There
          remain <a href="http://ruben.verborgh.org/blog/2013/11/29/the-lie-of-the-api/">
            questions</a> around how APIs can best be designed to publish data,
          and even if APIs are the most suitable way for publishing data at all. 
          Could the use of HTTP and URIs be sufficient? If the goal is to
          facilitate machine-readable data, what is best-practice? </p>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>APIs can be too clunky/rich in their functionality, which may
            increase the amount of calls necessary and size of data transferred,
            reducing performance.</li>
          <li>Collaboration between API providers and users is necessary to
            agree on 'useful' calls.</li>
          <li>API key agreements could restrict the openess of open data.</li>
          <li>Documentation accompanying APIs can be lacking.</li>
          <li>What is best practice for publishing streams of real-time data
            (with or without APIs)?</li>
          <li>Each resource should have one URI uniquly identifying it. There
            can then be different representations of the one resource (XML/HTML/JSON/RDF etc.)</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-AccessBulk">R-AccessBulk</a>
          and <a href="#R-AccessRealTime">R-AccessRealTime</a>.</p>
      </section>


    <!-- RDESC -->

      <section id="UC-RDESC" typeof="bibo:Chapter" resource="#UC-RDESC" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-RDESC">Resource Discovery for Extreme Scale Collaboration (RDESC)</h3>
        <p class="contributor">(Contributed by Sumit Purohit)<br />URL: <a href="http://rdesc.org/">http://rdesc.org/</a></p>
        <p>RDESC's objective is to develop a capability for describing, linking, searching 
          and discovering scientific resources used in collaborative science. For the purpose of capturing 
          semantic of context, RDESC adopt sets of existing ontologies where possible such as 
          <a href="http://xmlns.com/foaf/spec/"><abbr title="Friend of a Friend">FOAF</abbr></a>,
         <a href="http://bibliontology.com/"><abbr title="The Bibliographic Ontology">BIBO</abbr></a> and
        <a href="http://schema.org">schema.org</a>. RDESC also introduced new concepts in 
        order to provide a semantically integrated view of the data. Such concepts have two 
        distinct functions. The first is to preserve semantics of the source that are more specific 
        than what already existed in the ontology. The second is to provide broad categorization of 
        existing concepts as it becomes clear that concepts are forming general groups. These 
        generalizations enable users to work with concepts they understand, rather than needing to 
        understand the semantics of many different systems. It strive to provide lightweight enough 
        framework to be used as a component in any software system such as desktop user environments 
        or dashboards but also scalable to millions of resources.</p>

        <p><strong>Elements</strong></p><ul>
        <li><strong>Domains:</strong><ul><li>Scientific Resources: Instruments, Organizations, People</li>
          <li>Bibliographic Resources : Publications, Citations</li>
          <li>Physical Properties : soil moisture</li>
          <li>Digital Data Curation.</li></ul></li>
        <li><strong>Obligation/motivation:</strong><ul>
          <li>Show value to data publishers in publishing High Quality Linked Data based resources.</li>
          <li>Search/Browse/Discover semantically tagged data.</li>
          <li>Recommend "Similar" data.</li>
          <li>Use of RDFa, Schema.org in HTML to let standard web search engine index published pages.</li></ul></li>
        <li><strong>Usage: </strong><ul>
          <li>User providing more expressive queries to search data.</li>
          <li>User able to reach to as close as possible to the source of data.</li>
          <li>User able to find "Similar" data.</li></ul></li>
        <li><strong>Quality:</strong> is important to maintain correctness and quality of search result.</li>
        <li><strong>Size:</strong> Order of 1-2B triples as of 19 September 2014</li>
        <li><strong>Type/format:</strong> RDF LinkedData</li>
        <li><strong>Rate of change:</strong> No Formal Update Cycle as of now but data has been updated Quarterly</li>
        <li><strong>Potential audience:</strong> Scientific Community, Decision Makers</li>
        </ul>

        <p><strong>Positive aspects:</strong></p><ul>
          <li>Persistent URI with content negotiation. RDESC uses persistent URI to describe all the entities in the system.</li>
          <li>Use of existing ontologies such as foaf, bibo, schema.org</li>
          <li>Published specialized RDESC ontology for scientific resources : <a href="https://scm.escience.rpi.edu/svn/public/rdesc/ontologies/rdesc-core.ttl">RDESC Ontology</a> (Turtle)</li>
          <li>Enable application developers to use any kind of user interface suitable for their user needs.</li>
          <li>The provision of <a href="http://rdesc.org/examples">examples</a>.</li></ul> 

        <p><strong>Negative aspects:</strong></p><ul>
          <li>Difficulties in Data Curation</li></ul>

        <p><strong>Challenges:</strong></p><ul>
          <li>Scalability of such systems.</li>
          <li>Automated data curation pipelines.</li>
          <li>Metadata about Quality of Published Data.</li>
          <li>Frequency of Data Update..</li>
          <li>User Feedback for data correction/annotation</li></ul>

        <p><strong>Potential Requirements:</strong></p><ul>
          <li>Use of Persistent URIs.</li>
          <li>Recommending abstract and domain specific ontologies/vocabularies.</li>
          <li>Requirements to publish quality of published data.</li></ul>

        <p> <strong>Requires:</strong> 
          <a href="#R-UniqueIdentifier">R-UniqueIdentifier</a>,
          <a href="#R-Citable">R-Citable</a>,
          <a href="#R-Archiving">R-Archiving</a>,
          <a href="#R-TrackDataUsage">R-TrackDataUsage</a>,
          <a href="#R-AccessRealTime">R-AccessRealTime</a>,
          <a href="#R-SLAAvailable">R-SLAAvailable</a>,
          <a href="#R-FormatStandardized">R-FormatStandardized</a>,
          <a href="#R-VocabOpen">R-VocabOpen</a>,
          <a href="#R-PersistentIdentification">R-PersistentIdentification</a>,
          <a href="#R-VocabReference">R-VocabReference</a>,
          <a href="#R-SelectHighValue">R-SelectHighValue</a>, 
          <a href="#R-SelectDemand">R-SelectDemand</a>,
          <a href="#R-ProvAvailable">R-ProvAvailable</a>,
          <a href="#R-DataUnavailabilityReference">R-DataUnavailabilityReference</a>,
          <a href="#R-DataMissingIncomplete">R-DataMissingIncomplete</a>,
          <a href="#R-DataLifecyclePrivacy">R-DataLifecyclePrivacy</a> and
          <a href="#R-SensitiveSecurity">R-SensitiveSecurity</a>.</p>
      </section>
    </section>
    <section id="general-challenges" rel="bibo:Chapter" resource="#challenges" typeof="bibo:Chapter">
      <h2 role="heading" aria-level="1" id="challenges">General Challenges</h2>
      <p>The use cases presented in the previous section illustrate a number of
        challenges faced by data publishers and data consumers. These challenges
        show that some guidance is required on specifc areas and therefore best
        practices should be provided. According to the challenges, a set of
        requirements were defined in such a way that a requirement motivates the
        creation of one or more best practices. Challenges related to Data
        Qaulity and Data Usage motivated the definition of specifc requirements
        for the Quality and Granularity Description Vocabulary and the Data
        Usage Vocabulary. </p>

    <section typeof="bibo:Chapter" resource="#openclosed" rel="bibo:Chapter">
      <h3 id="openclosed" aria-level="2" role="heading" >A Word on Open and Closed Data</h3>
      <p>The Open Knowledge Foundation <a href="http://opendefinition.org/">defines open data</a> 
      most succinctly as <em>data
      that can be freely used, modified, and shared by anyone for any purpose</em>.
      Data on the Web may be open but Web technologies are equally applicable to data
      that is not open, or to scenarios where open and closed data are combined.
      There are a number of areas where data may be on the Web but not open.</p><ol>
      <li><strong>Behind The Firewall</strong>
      <p>Closed data may be generated in an organization that then blocks general access using a firewall or 
      other access control system. Generated data may have links to other "open" data hosted 
      elsewhere and it may be represented using open Web standards but this cannot be considered "open data."</p></li>
      <li><strong>Proprietary data by policy</strong>
      <p>Data can be closed through the policies of the data publisher and data provider. 
      Business-sensitive data that is not made accessible to rest of the world is an 
      example of closed data. Data controlled by law or government policies 
      are further examples of closed data e.g. national security data, law enforcement, health care etc.</p></li>
      <li><strong>Lifecycle state of data</strong>
      <p>There is often a period between the generation of data and its publication as open data 
      and data in this state should be considered as "closed." The data may remain in a 
      closed state for an indefinite period of time while it is validated and analyzed, 
      and insights and discoveries are published. It may also remain closed because 
      the data publisher prefers to maximize their advantage gained by availability 
      of data before they publish it openly. This is current common practice in 
      scientific research.</p></li>
      <li><strong>Non HTTP protocol based data</strong>
      <p>Historically data has been exposed using various non-HTTP IETF protocol based end points including, 
       but not limited to FTP, SFTP, SCP, Rsync. While these protocols are considered "open," 
       their inter-operability with HTTP based Web protocol is currently a limiting factor. 
       From an open data perspective, data only available using these these non-HTTP protocols 
      should be considered as closed data and, by definition, is not on the Web. 
      It follows that data accessibile by private or application-specific proprietary 
      access protocol end points are also deemed as both closed data and out of scope for data on the Web.</p></li></ol>
 
    </section>

      <table>
        <tbody>
          <tr>
            <th>Challenge</th>
            <th>Requirements</th>
            <th><br />
            </th>
          </tr>
          <tr>
            <td>Data Formats</td>
            <td> <a href="#h4_can-req-Formats">Requirements for Data Formats </a>
            </td>
            <td> <a href="#R-FormatMachineRead">R-FormatMachineRead</a>, <a href="#R-FormatStandardized">R-FormatStandardized</a>,
              <a href="#R-FormatOpen">R-FormatOpen</a>, <a href="#R-FormatMultiple">R-FormatMultiple</a>,
              <a href="#R-FormatLocalize">R-FormatLocalize</a> </td>
          </tr>
          <tr>
            <td>Data Vocabularies</td>
            <td> <a href="#h4_can-req-vocabularies">Requirements for Data
                Vocabularies </a> </td>
            <td> <a href="#R-VocabReference">R-VocabReference </a>, <a href="#R-VocabDocum">R-VocabDocum</a>,
              <a href="#R-VocabOpen">R-VocabOpen</a>, <a href="#R-VocabVersion">R-VocabVersion</a>
            </td>
          </tr>
          <tr>
            <td>Metadata</td>
            <td> <a href="#h4_can-req-metadata">Requirements for Metadata</a> </td>
            <td> <a href="#R-MetadataAvailable">R-MetadataAvailable</a>,<a href="#R-MetadataMachineRead">R-MetadataMachineRead</a>,
              <a href="#R-MetadataStandardized">R-MetadataStandardized</a>, <a

                href="#R-MetadataDocum">R-MetadataDocum</a> </td>
          </tr>
          <tr>
            <td>Licenses</td>
            <td> <a href="#h4_can-req-licenses">Requirements for Licenses </a>
            </td>
            <td> <a href="#R-LicenseAvailable">R-LicenseAvailable</a>, <a href="#R-LicenseLiability">R-LicenseLiability</a>
            </td>
          </tr>
          <tr>
            <td>Provenance</td>
            <td> <a href="#h4_can-req-provenance">Requirements for Provenance </a>
            </td>
            <td> <a href="#R-ProvAvailable">R-ProvAvailable</a> </td>
          </tr>
          <tr>
            <td>Industry-reuse</td>
            <td> <a href="#h4_can-req-industry-reuse">Requirements for Industry
                reuse </a> </td>
            <td> <a href="#R-SLAAvailable">R-SLAAvailable</a>, <a href="#R-IndustryReuse">R-IndustryReuse</a>,
              <a href="#R-PotentialRevenue">R-PotentialRevenue</a> </td>
          </tr>
          <tr>
            <td>Data Granularity</td>
            <td> <a href="#h4_can-req-granularity">Requirements for Data
                Granularity </a> </td>
            <td> <a href="#R-GranularityLevels">R-GranularityLevels</a> </td>
          </tr>
          <tr>
            <td>Data Selection</td>
            <td><a href="#h4_can-req-selection">Requirements for Data Selection </a> </td>
            <td><a href="#R-SelectHighValue">R-SelectHighValue</a>, 
                <a href="#R-SelectDemand">R-SelectDemand</a>,
                <a href="#R-DataLifecyclePrivacy">R-DataLifecyclePrivacy</a>
            </td>
          </tr>
          <tr>
            <td>Data Access</td>
            <td> <a href="#h4_can-req-access">Requirements for Data Access </a>
            </td>
            <td> <a href="#R-AccessBulk">R-AccessBulk</a>, <a href="#R-AccessRealTime">R-AccessRealTime</a>,
              <a href="#R-AccessUptodate">R-AccessUptodate</a> </td>
          </tr>
          <tr>
            <td>Sensitive Data</td>
            <td> <a href="#h4_can-req-sensitive">Requirements for Sensitive Data</a> </td>
            <td> <a href="#R-SensitivePrivacy">R-SensitivePrivacy</a>, <a href="#R-SensitiveSecurity">R-SensitiveSecurity</a>
                  <a href="#R-DataUnavailabilityReference">R-DataUnavailabilityReference</a>
            </td>
          </tr>
          <tr>
            <td>Data Identification</td>
            <td> <a href="#h4_can-req-identification">Requirements for Data Identification </a> </td>
            <td> <a href="#R-UniqueIdentifier">R-UniqueIdentifier</a>, <a href="#R-MultipleRepresentations">R-MultipleRepresentations</a>
            </td>
          </tr>
          <tr>
            <td>Data Publication</td>
            <td> <a href="#h4_can-req-publication">Requirements for Data Publication </a> </td>
            <td> <a href="#R-SynchronizedData">R-SynchronizedData</a>, <a href="#R-CoreRegister">R-CoreRegister</a>
            </td>
          </tr>
          <tr>
            <td>Persistence</td>
            <td> <a href="#h4_can-req-persistence">Requirements for Persistence</a> </td>
            <td> <a href="#R-PersistentIdentification">R-PersistentIdentification</a>,
              <a href="#R-Archiving">R-Archiving</a> </td>
          </tr>
          <tr>
            <td>Data Quality</td>
            <td> <a href="#h4_can-req-quality">Requirements for Data Quality </a>
            </td>
            <td> <a href="#R-QualityCompleteness">R-QualityCompleteness</a>, 
                 <a href="#R-QualityComparable">R-QualityComparable</a>, 
                 <a href="#R-QualityMetrics">R-QualityMetrics</a>,
                 <a href="#R-QualityOpinions">R-QualityOpinions</a>, 
                 <a href="#R-DataMissingIncomplete">R-DataMissingIncomplete</a> </td>
          </tr>
          <tr>
            <td>Data Usage</td>
            <td> <a href="#h4_can-req-usage">Requirements for Data Usage </a>
            </td>
            <td> <a href="#R-TrackDataUsage">R-TrackDataUsage</a>, <a href="#R-IncorporateFeedback">R-IncorporateFeedback</a>,
              <a href="#R-Citable">R-Citable</a> </td>
          </tr>
        </tbody>
      </table>
    </section>

    <section id="requirements-1" rel="bibo:Chapter" resource="#requirements" typeof="bibo:Chapter">
      <h2 role="heading" aria-level="1" id="requirements">Requirements</h2>

      <section id="requirements-for-data-on-the-web-best-practices" rel="bibo:Chapter"  resource="#req1" typeof="bibo:Chapter">
        <h3 role="heading" aria-level="2" id="req1">Requirements for Data on the Web Best Practices </h3>
        <section id="requirements-for-data-formats" rel="bibo:Chapter" resource="#h4_can-req-Formats" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-Formats">Requirements for Data Formats</h4>
          <dl>
            <dt id="R-FormatMachineRead">R-FormatMachineRead</dt>
            <dd>
              <p id="_R-FormatMachineRead"><em>Data should be available in a
                  machine-readable format that is adequate for its intended or
                  potential use</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-BuildingEye">BuildingEye</a>
                and <a href="#UC-TheLandPortal">TheLandPortal</a> </p>
            </dd>
            <dt id="R-FormatStandardized">R-FormatStandardized</dt>
            <dd>
              <p id="_R-FormatStandardized"><em>Data should be availabe in a
                  standardized format. Through standardization, interoperability
                  is also expected.</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-OpenCityDataPipeline">OpenCityDataPipeline</a>,
                <a href="#UC-WindCharacterizationScientificStudy">WindCharacterizationScientificStudy</a>,
                <a href="#UC-BuildingEye">BuildingEye</a> , <a href="#UC-TheLandPortal">TheLandPortal</a>,
                <a href="#UC-GS1-Digital">GS1 Digital</a>, <a href="#UC-Tabulae">Tabulae</a> and
                 <a href="#UC-RDESC">RDESC</a>.</p>
            </dd>
            <dt id="R-FormatOpen">R-FormatOpen</dt>
            <dd>
              <p id="_R-FormatOpen"><em>Data should be availabe in an open format</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-BuildingEye">BuildingEye</a>
                , </p>
            </dd>
            <dt id="R-FormatMultiple">R-FormatMultiple</dt>
            <dd>
              <p id="_R-FormatMultiple"><em>Data should be availabe in multiple formats</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-GS1-Digital">GS1 Digital</a> </p>
            </dd>
            <dt id="R-FormatLocalize">R-FormatLocalize</dt>
            <dd>
              <p id="_R-FormatLocalize"><em>Information about locale parameters
                  (date and number formats, language) should be made available</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-TheLandPortal">TheLandPortal</a>
                and <a href="#UC-Tabulae">Tabulae</a> </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-data-vocabularies" rel="bibo:Chapter" resource="#h4_can-req-vocabularies" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-vocabularies">Requirements for Data Vocabularies</h4>
          <dl>
            <dt id="R-VocabReference">R-VocabReference</dt>
            <dd>
              <p id="_R-VocabReference"><em>Existing reference vocabularies
                  should be reused where possible</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-OpenCityDataPipeline">OpenCityDataPipeline</a>,
                <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>,
                <a href="#UC-DadosGovBr">DadosGovBr</a>, <a href="#UC-ISOGEOStory">ISOGEOStory</a>,
                <a href="#UC-DutchBasicRegisters">DutchBaseRegisters</a>, 
                <a href="#UC-DigitalArchivingofLinkedData">DigitalArchivingofLinkedData</a>,
                <a href="#UC-TheLandPortal">TheLandPortal</a>, 
                <a href="#UC-UruguayOpenDataCatalogue">UruguayOpenDataCatalogue</a>,
                <a href="#UC-Tabulae">Tabulae</a> and
                 <a href="#UC-RDESC">RDESC</a>. </p>
            </dd>
            <dt id="R-VocabDocum">R-VocabDocum</dt>
            <dd>
              <p id="_R-VocabDocum"><em>Vocabularies should be clearly documented</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a></p>
            </dd>
            <dt id="R-VocabOpen">R-VocabOpen</dt>
            <dd>
              <p id="_R-VocabOpen"><em>Vocabularies should be shared in an open way</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>,
                <a href="#UC-WindCharacterizationScientificStudy">WindCharacterizationScientificStudy</a> and
                 <a href="#UC-RDESC">RDESC</a>. </p>
            </dd>
            <dt id="R-VocabVersion">R-VocabVersion</dt>
            <dd>
              <p id="_R-VocabVersion"><em>Vocabularies should include versioning information</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-TheLandPortal">TheLandPortal</a>
                and <a href="#UC-Tabulae">Tabulae</a> </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-metadata" rel="bibo:Chapter" resource="#h4_can-req-metadata" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-metadata">Requirements for Metadata</h4>
          <dl>
            <dt id="R-MetadataAvailable">R-MetadataAvailable</dt>
            <dd>
              <p id="_R-MetadataAvailable"><em>Metadata should be available</em></p>
              <p><strong>Motivation:</strong> <a href="#UC-ViolenceMap">ViolenceMap</a></p>
            </dd>
            <dt id="R-MetadataMachineRead">R-MetadataMachineRead</dt>
            <dd>
              <p id="_R-MetadataMachineRead"><em>Metadata should be  machine-readable</em></p>
              <p><strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>,
                <a href="#UC-Bio2RDF">Bio2RDF</a> and <a href="#UC-TheLandPortal">TheLandPortal</a></p>
            </dd>
            <dt id="R-MetadataStandardized">R-MetadataStandardized</dt>
            <dd>
              <p id="_R-MetadataStandardized"><em>Metadata should be
                  standardized. Through standardization, interoperability is
                  also expected.</em></p>
              <p><strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>,
                <a href="#UC-ISOGEOStory">ISOGEOStory</a> and <a href="#UC-LATimesReporting">LATimesReporting</a></p>
            </dd>
            <dt id="R-MetadataDocum">R-MetadataDocum</dt>
            <dd>
              <p id="_R-MetadatDocum"><em>Metadata vocabulary, or values if
                  vocabulary is not standardized, should be well-documented</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>
              </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-licenses" rel="bibo:Chapter" resource="#h4_can-req-licenses" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-licenses">Requirements  for Licenses</h4>
          <p>Note: Licenses are a form of metadata and so inherit metadata requirements.</p>
          <dl>
            <dt id="R-LicenseAvailable">R-LicenseAvailable</dt>
            <dd>
              <p id="LicenseAvailable">Data should be associated with a
                  license. License is a type of metadata, so all metadata
                  requirements also apply here.</p>
              <p> <strong>Motivation:</strong> <a href="#UC-MachineReadabilityandInteroperabilityofLicenses">MachineReadabilityandInteroperabilityofLicenses</a>,
                <a href="#UC-DadosGovBr">DadosGovBr</a> and <a href="#UC-BuildingEye">BuildingEye</a>.</p>
            </dd>
            <dt id="R-LicenseLiability">R-LicenseLiability</dt>
            <dd>
              <p id="LicenseLiability"><em>Liability terms associated with usage
                  of Data on the Web should be clearly outlined</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-GS1-Digital">GS1 Digital</a> </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-provenance" rel="bibo:Chapter" resource="#h4_can-req-provenance" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-provenance">Requirements for Provenance</h4>
          <p>Note: Provenance data is a form of metadata and so inherits metadata requirements.</p>
          <dl>
            <dt id="R-ProvAvailable">R-ProvAvailable</dt>
            <dd>
              <p id="ProvAvailable"><em>Data provenance information should be
                  available. Provenance </em>data i<em>s a type of metadata, so
                  all metadata requirements also apply here. </em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-TheLandPortal">TheLandPortal</a>,
                <a href="#UC-GS1-Digital">GS1 Digital</a>, <a href="#UC-Tabulae">Tabulae</a> and
                 <a href="#UC-RDESC">RDESC</a>.</p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-industry-reuse" rel="bibo:Chapter" resource="#h4_can-req-industry-reuse" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-industry-reuse">Requirements for Industry Reuse</h4>
          <p>Note: SLAs are a form of metadata and so inherit metadata requirements</p>
          <dl>
            <dt id="R-SLAAvailable">R-SLAAvailable</dt>
            <dd>
              <p id="SLAAvailable"><em>Service Level Agreements (SLAs) for
                  industry reuse of the data should be available if requested (via a defined contact point).
                  An SLA is </em><em>a type of metadata, so all metadata
                  requirements also apply here.</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DocumentedSupportandRelease">DocumentedSupportandRelease</a>,
                <a href="#UC-MachineReadabilityofSLAs">MachineReadabilityofSLAs</a> and
                 <a href="#UC-RDESC">RDESC</a>.
              </p>
            </dd>
            <dt id="R-IndustryReuse">R-IndustryReuse</dt>
            <dd>
              <p id="IndustryReuse"><em>Data should be suitable for industry reuse</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-OpenCityDataPipeline">OpenCityDataPipeline</a>
              </p>
            </dd>
            <dt id="R-PotentialRevenue">R-PotentialRevenue</dt>
            <dd>
              <p id="PotentialRevenue"><em>Potential revenue streams from data  should be described</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DutchBasicRegisters">DutchBaseRegisters</a>
              </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-data-granularity" rel="bibo:Chapter" resource="#h4_can-req-granularity" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-granularity">Requirements for Data Granularity</h4>
          <dl>
            <dt id="R-GranularityLevels">R-GranularityLevels</dt>
            <dd>
              <p id="_R-GranularityLevels"><em>Data available at different
                  levels of granularity should be accessible and modelled in a
                  common way</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-ISOGEOStory">ISOGEOStory</a>
                and <a href="#UC-TheLandPortal">TheLandPortal</a> </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-data-selection" rel="bibo:Chapter" resource="#h4_can-req-selection" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-selection">Requirements for Data Selection</h4>
          <dl>
            <dt id="R-SelectHighValue">R-SelectHighValue</dt>
            <dd>
              <p id="_R-SelectHighValue"><em>Datasets selected for publication
                  should be of high-value, which should be indicated in a
                  quantifiable manner/property.</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a> and
                 <a href="#UC-RDESC">RDESC</a>.
              </p>
            </dd>
            <dt id="R-SelectDemand">R-SelectDemand</dt>
            <dd>
              <p id="_R-SelectDemand"><em>Datasets selected for publication
                  should be in demand by potential users, which should be
                  indicated in a quantifiable manner/property.</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a> and
                 <a href="#UC-RDESC">RDESC</a>.</p>
            </dd>
            <dt id="R-DataLifecyclePrivacy">R-DataLifecyclePrivacy</dt>
            <dd><p id="_R-DataLifecyclePrivacy"><em>Preliminary steps in the data lifecycle should not infringe upon individual’s intellectual property rights</em>.</p>
              <p><strong>Motivation:</strong> 
              <a href="#UC-BuildingEye">BuildingEye</a>,
              <a href="#UC-Bio2RDF">Bio2RDF</a>,
              <a href="#UC-RDESC">RDESC</a>.</p></dd>
          </dl>
        </section>
        <section id="requirements-for-data-access" rel="bibo:Chapter" resource="#h4_can-req-access" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-access">Requirements for Data Access</h4>
          <dl>
            <dt id="R-AccessBulk">R-AccessBulk</dt>
            <dd>
              <p id="_R-AccessBulk"><em>Data should be available for bulk  download</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-PublicationofDataviaAPIs">PublicationofDataviaAPIs</a>,
                <a href="#UC-BuildingEye">BuildingEye</a> and <a href="#UC-TheLandPortal">TheLandPortal</a>
              </p>
            </dd>
            <dt id="R-AccessRealTime">R-AccessRealTime</dt>
            <dd>
              <p id="_R-AccessRealTime"><em>Where data is produced in real-time,
                  it should be available on the Web in real-time</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-PublicationofDataviaAPIs">PublicationofDataviaAPIs</a>,
                <a href="#UC-WindCharacterizationScientificStudy">WindCharacterizationScientificStudy</a>,
                 <a href="#UC-TheLandPortal">TheLandPortal</a> and
                 <a href="#UC-RDESC">RDESC</a>. </p>
            </dd>
            <dt id="R-AccessUptodate">R-Access Up to date</dt>
            <dd>
              <p id="_R-AccessUptodate"><em>Data should be available in an up-to-date manner and the update cycle made explicit</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DocumentedSupportandRelease">Documented Support and Release</a>
                and <a href="#UC-GS1-Digital">GS1 Digital</a> </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-sensitive-data" rel="bibo:Chapter" resource="#h4_can-req-sensitive" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-sensitive">Requirements for Sensitive Data</h4>
          <dl>
            <dt id="R-SensitivePrivacy">R-SensitivePrivacy</dt>
            <dd>
              <p id="_R-SensitivePrivacy"><em>Data should not infringe a person's right to privacy</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DutchBasicRegisters">DutchBaseRegisters</a></p>
            </dd>
            <dt id="R-SensitiveSecurity">R-SensitiveSecurity</dt>
            <dd>
              <p id="_RSensitiveSecurity"><em>Data should not infringe an organization's security (local government, national government, business)</em></p>
              <p><strong>Motivation:</strong> <a href="#UC-DatasetsforNaturalHazardsManagement">DatasetsforNaturalHazardsManagement</a></p>
            </dd>

            <dt id="R-DataUnavailabilityReference"><em>R-DataUnavailabilityReference</em></dt>
            <dd><p>References to data that is not open, or is available under 
            different restrictions to the origin of the reference, should provide
            context by explaining how or by whom the referred to data can be accessed.</p>
            <p><strong>Motivation:</strong> 
            <a href="#UC-BuildingEye">BuildingEye</a>,
            <a href="#UC-DutchBasicRegisters">DutchBaseRegisters</a>,
            <a href="#UC-DigitalArchivingofLinkedData">DigitalArchivingofLinkedData</a>,
            <a href="#UC-UruguayOpenDataCatalogue">UruguayOpenDataCatalog</a>,
            <a href="#UC-Bio2RDF">Bio2RDF</a>,
            <a href="#UC-OKFNTransportWG">OKFNTransportWG</a>,
            <a href="#UC-RDESC">RDESC</a>.</p>
            </dd>

          </dl>
        </section>
        <section id="requirements-for-data-identification" rel="bibo:Chapter" resource="#h4_can-req-identification" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-identification">Requirements  for Data Identification</h4>
          <dl>
            <dt id="R-UniqueIdentifier">R-UniqueIdentifier</dt>
            <dd>
              <p id="UniqueIdentifier"><em>Each data resource should be associated with a unique identifier</em></p>
              <p><strong>Motivation:</strong> <a href="#UC-DutchBasicRegisters">DutchBaseRegisters</a>, 
                 <a href="#UC-DigitalArchivingofLinkedData">DigitalArchivingofLinkedData</a>,
                 <a href="#UC-LATimesReporting">LATimesReporting</a>, 
                 <a href="#UC-UruguayOpenDataCatalogue">UruguayOpenDataCatalogue</a> and
                 <a href="#UC-RDESC">RDESC</a>.
              </p>
            </dd>
            <dt id="R-MultipleRepresentations">R-MultipleRepresentations</dt>
            <dd>
              <p id="MultipleRepresentations"><em>A data resource may have multiple representations, e.g. xml/html/json/rdf</em></p>
              <p><strong>Motivation:</strong> <a href="#UC-DutchBasicRegisters">DutchBaseRegisters</a></p>
            </dd>
            <dt id="R-Citable">R-Citable</dt>
            <dd>
              <p id="_R-Citable"><em>It should be possible to cite data on the Web</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-LATimesReporting">LATimesReporting</a>,
                <a href="#UC-GS1-Digital">GS1 Digital</a> and
                 <a href="#UC-RDESC">RDESC</a>. </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-data-publication" rel="bibo:Chapter" resource="#h4_can-req-publication" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-publication">Requirements for Data Publication</h4>
          <dl>
            <dt id="R-DynamicGeneration">R-SynchronizedData</dt>
            <dd>
              <p id="DynamicGeneration"><em>Dynamic generation of Data on the
                  Web from non-Web data resources and a</em><em>utomatic update
                  when original data source is updated</em></p>
              <strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>,
              <a href="#UC-UruguayOpenDataCatalogue">UruguayOpenDataCatalogue</a>,
              <a href="#UC-GS1-Digital">GS1 Digital</a> , <a href="#UC-Tabulae">Tabulae</a>,
              <a href="#UC-ViolenceMap">ViolenceMap</a> </dd>
            <dt id="R-CoreRegister">R-CoreRegister</dt>
            <dd>
              <p id="_CoreRegister"><em>Core registers should be accessible</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DutchBasicRegisters">DutchBaseRegisters</a>
                and <a href="#UC-GS1-Digital">GS1 Digital</a> </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-persistence" rel="bibo:Chapter" resource="#h4_can-req-persistence" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-persistence">Requirements for Persistence</h4>
          <dl>
            <dt id="R-PersistentIdentification">R-PersistentIdentification</dt>
            <dd>
              <p id="Persistent"><em>An identifier for a particular resource should be resolvable on the Web and associated for the foreseeable future with a single resource or with information about why the resource is no longer available.</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DigitalArchivingofLinkedData">DigitalArchivingofLinkedData</a>,
                <a href="#UC-TheLandPortal">TheLandPortal</a>, 
                <a href="#UC-DutchBasicRegisters">DutchBaseRegisters</a>, <a href="#UC-GS1-Digital">GS1
                  Digital</a>, <a href="#UC-ViolenceMap">ViolenceMap</a> and
                 <a href="#UC-RDESC">RDESC</a>. </p>
            </dd>
            <dt id="R-Archiving">R-Archiving</dt>
            <dd>
              <p id="PersArchiving"><em>It should be possible to archive data</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DigitalArchivingofLinkedData">DigitalArchivingofLinkedData</a>  and
                 <a href="#UC-RDESC">RDESC</a>.
              </p>
            </dd>
          </dl>
        </section>
      </section>
      <section id="requirements-for-quality-and-granularity-description-vocabulary" rel="bibo:Chapter" resource="#req2" typeof="bibo:Chapter">
        <h3 role="heading" aria-level="2" id="req2">Requirements for Quality and Granularity Description Vocabulary</h3>
        <section id="requirements-for-data-quality" rel="bibo:Chapter" resource="#h4_can-req-quality" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-quality"> <span class="secno">4.2.1
              </span>Requirements for Data Quality</h4>
          <dl>
            <dt id="R-QualityCompleteness">R-QualityCompleteness</dt>
            <dd>
              <p id="_R-QualityCompleteness"><em>Data should be complete</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-OpenCityDataPipeline">OpenCityDataPipeline</a>,
                <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>,
                <a href="#UC-TheLandPortal">TheLandPortal</a>, <a href="#UC-Tabulae">Tabulae</a>
                and <a href="#UC-ViolenceMap">ViolenceMap</a>. </p>
            </dd>

            <dt id="R-DataMissingIncomplete">R-DataMissingIncomplete</dt>
            <dd>
              <p id="_R-DataMissingIncomplete"><em>Publishers should indicate if data is partially missing or if the dataset is incomplete</em></p>
              <p><strong>Motivation:</strong> 
              <a href="#UC-BuildingEye">BuildingEye</a>,
              <a href="#UC-LATimesReporting">LATimesReporting</a>,
              <a href="#UC-UruguayOpenDataCatalogue">UruguayOpenDataCatalogue</a>,
              <a href="#UC-OKFNTransportWG">#UC-OKFNTransportWG</a>,
              <a href="#UC-RDESC">RDESC</a>.</p>
            </dd>


            <dt id="R-QualityComparable">R-QualityComparable</dt>
            <dd>
              <p id="_R-QualityComparable"><em>Data should be comparable with
                  other datasets</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-OpenCityDataPipeline">OpenCityDataPipeline</a></p>
            </dd>
            <dt id="R-QualityMetrics">R-QualityMetrics</dt>
            <dd>
              <p id="_R-QualityMetrics"><em>Data should be associated with a set
                  of standardized, objective quality metrics</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-TheLandPortal">TheLandPortal</a>
              </p>
            </dd>
            <dt id="R-QualityOpinions">R-QualityOpinions</dt>
            <dd>
              <p id="_R-QualityOpinions"><em>Subjective quality opinions on the
                  data should be supported</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-FeedbackLoopforCorrections">FeedbackLoopforCorrections</a>
                and <a href="#UC-DadosGovBr">DadosGovBr</a> </p>
            </dd>
          </dl>
        </section>
      </section>
      <section id="requirements-for-data-usage-description-vocabulary" rel="bibo:Chapter" resource="#req3" typeof="bibo:Chapter">
        <h3 role="heading" aria-level="2" id="req3">Requirements for Data Usage Description Vocabulary</h3>
        <section id="requirements-for-data-usage" rel="bibo:Chapter" resource="#h4_can-req-usage" typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-usage">Requirements for Data Usage</h4>
          <dl>
            <dt id="R-TrackDataUsage">R-TrackDataUsage</dt>
            <dd>
              <p id="_R-TrackDataUsage"><em>It should be possible to track the usage of data</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-TrackingofDataUsage">TrackingofDataUsage</a> and
                 <a href="#UC-RDESC">RDESC</a>.
              </p>
            </dd>
            <dt id="R-IncorporateFeedback">R-IncorporateFeedback</dt>
            <dd>
              <p id="_R-IncorporateFeedback"><em>It should be possible to incorporate feedback on the data</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-FeedbackLoopforCorrections">FeedbackLoopforCorrections</a></p>
            </dd>
          </dl>
        </section>
      </section>
    </section>
    <section id="reading-material-1" rel="bibo:Chapter" resource="#reading-material" typeof="bibo:Chapter">
      <h2 role="heading" aria-level="1" id="reading-material">Reading Material</h2>
      <section id="general-resources-1" rel="bibo:Chapter" resource="#general-resources" typeof="bibo:Chapter">
        <h3 role="heading" aria-level="2" id="general-resources">General Resources</h3>
        <ul>
          <li><a href="http://www.w3.org/TR/ld-glossary/" class="external text">Government
              Linked Data (GLD) Glossary of Terms</a></li>
          <li><a href="http://lov.okfn.org/dataset/lov/" class="external text">Open
              Knowledge Foundation (OKFN) Linked Open Vocabulary Browser</a></li>
          <li><a href="http://www.w3.org/TR/ld-bp/" class="external text">Best
              Practices for Publishing Linked Data</a></li>
          <li><a href="http://philarcher.org/diary/2013/uripersistence/" class="external text">
              10 Rules for Persistent URIs</a></li>
          <li><a href="http://www.w3.org/2012/ldp/" class="external text">Linked
              Data Platform Working Group</a></li>
          <li>The <a href="http://www.prelida.eu/" class="external text">PRELIDA</a>
            and <a href="http://www.diachron-fp7.eu/">Diachron</a> projects are
            concerned with preserving <abbr title="Linked Open Data">LOD</abbr></li>
        </ul>
      </section>
      <section id="relevant-vocabularies" rel="bibo:Chapter" resource="#relevant-vocabs" typeof="bibo:Chapter">
        <h3 role="heading" aria-level="2" id="relevant-vocabs">Relevant Vocabularies</h3>
        <ul>
          <li><a href="http://www.w3.org/TR/vocab-org/" class="external text">The Organization Ontology (ORG)</a></li>
          <li><a href="http://www.w3.org/TR/vocab-dcat/" class="external text">Data Catalog Vocabulary(DCAT)</a></li>
          <li><a href="http://www.w3.org/TR/vocab-data-cube/" class="external text">The RDF Data Cube Vocabulary (QB)</a></li>
          <li><a href="http://www.w3.org/TR/prov-o/" class="external text">The Provenance (PROV) Ontology</a></li>
          <li><a href="http://www.w3.org/TR/skos-reference/" class="external text">Simple Knowledge Organization System Reference (SKOS)</a></li>
        </ul>
      </section>
      <section id="communities-of-interest-1" rel="bibo:Chapter" resource="#communities-of-interest" typeof="bibo:Chapter">
        <h3 role="heading" aria-level="2" id="communities-of-interest">Communities of Interest</h3>
        <ul>
          <li><a href="http://www.w3.org/2013/data/" class="external text"><abbr title="World Wide Web Consortium">W3C</abbr> Data Activity</a></li>
          <li><a href="http://www.w3.org/2013/05/lcsv-charter.html" class="external text"><abbr title="World Wide Web Consortium">W3C</abbr> Comma Separated  Values (CSV) On the Web Working Group</a>
            <ul>
              <li><a href="http://www.w3.org/TR/csvw-ucr/" class="external text">CSV On the Web Use Cases</a></li>
            </ul>
          </li>
          <li><a href="http://www.w3.org/2011/gld/charter.html" class="external text"><abbr title="World Wide Web Consortium">W3C</abbr> Government Linked Data Working Group</a> (This WG is now closed but in some respects is the forerunner of the DWBP)</li>
          <li><a href="http://www.w3.org/2011/07/privacy-ig-charter.html" class="external text"><abbr title="World Wide Web Consortium">W3C</abbr> Privacy on the Web(PING) Working Group</a></li>
        </ul>
      </section>
    </section>
    <section rel="bibo:Chapter" resource="#acknowledgements" typeof="bibo:Chapter" class="appendix" id="acknowledgements">
      <h2 id="h2_acknowledgements" role="heading" aria-level="1">Acknowledgements</h2>
      <p>The editors wish to thank all those who have contributed use cases or commented on those provided by others.</p>
    </section>
    <section rel="bibo:Chapter" resource="#change-history" typeof="bibo:Chapter" class="appendix" id="change-history">
      <h2 id="h2_change-history" role="heading" aria-level="1">Change history</h2><ul>
      <li>Tracking Data Use cases extended to include Ordnance Survey</li>
      <li>RDESC use case added</li>
      <li>General imrpovements in language style and consistency</li>
      <li>Definition of PersistentIdentification modified to emphasize Web aspect.</li>
      <li>New requirements added related to closed data.</li>
      </ul>
    </section>
  </body>
</html>
